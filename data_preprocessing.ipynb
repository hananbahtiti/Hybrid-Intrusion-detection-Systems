{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-zW0--TET_w0"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hananbahtiti/Hybrid-Intrusion-detection-Systems/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Dataset"
      ],
      "metadata": {
        "id": "-zW0--TET_w0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDSozQi9-uwW",
        "outputId": "e8456024-0d3f-4db3-edce-10d7c1c76dee",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-26 08:47:38--  https://unsworks.unsw.edu.au/bitstreams/0ac2820a-5131-43ab-90b2-c624c8d73649/download\n",
            "Resolving unsworks.unsw.edu.au (unsworks.unsw.edu.au)... 54.253.215.118\n",
            "Connecting to unsworks.unsw.edu.au (unsworks.unsw.edu.au)|54.253.215.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://unsworks.unsw.edu.au/server/api/core/bitstreams/0ac2820a-5131-43ab-90b2-c624c8d73649/content [following]\n",
            "--2025-04-26 08:47:40--  https://unsworks.unsw.edu.au/server/api/core/bitstreams/0ac2820a-5131-43ab-90b2-c624c8d73649/content\n",
            "Reusing existing connection to unsworks.unsw.edu.au:443.\n",
            "HTTP request sent, awaiting response... 200 200\n",
            "Length: unspecified [application/x-rar-compressed]\n",
            "Saving to: ‘NGIDS-DS.rar’\n",
            "\n",
            "NGIDS-DS.rar            [                <=> ] 941.51M  17.3MB/s    in 56s     \n",
            "\n",
            "2025-04-26 08:48:36 (16.8 MB/s) - ‘NGIDS-DS.rar’ saved [987249484]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O NGIDS-DS.rar https://unsworks.unsw.edu.au/bitstreams/0ac2820a-5131-43ab-90b2-c624c8d73649/download"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/NGIDS-DS.rar"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XyP_2zMAbEn",
        "outputId": "1df0d946-b231-460b-8820-934a7f6aed8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/NGIDS-DS.rar\n",
            "\n",
            "Creating    NGIDS                                                     OK\n",
            "Creating    NGIDS/NGIDS-DS-v1                                         OK\n",
            "Extracting  NGIDS/NGIDS-DS-v1/feature_descr.csv                          \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/ground_truth.csv                           \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Creating    NGIDS/NGIDS-DS-v1/host logs                               OK\n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/1.csv                            \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/10.csv                           \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/11.csv                           \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/12.csv                           \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/13.csv                           \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/14.csv                           \b\b\b\b  2%\b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/15.csv                           \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/16.csv                           \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/17.csv                           \b\b\b\b  3%\b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/18.csv                           \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/19.csv                           \b\b\b\b  4%\b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/2.csv                            \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/20.csv                           \b\b\b\b  5%\b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/21.csv                           \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/22.csv                           \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/23.csv                           \b\b\b\b  6%\b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/24.csv                           \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/25.csv                           \b\b\b\b  7%\b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/26.csv                           \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/27.csv                           \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/28.csv                           \b\b\b\b  8%\b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/29.csv                           \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/3.csv                            \b\b\b\b  9%\b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/30.csv                           \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/31.csv                           \b\b\b\b 10%\b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/32.csv                           \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/33.csv                           \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/34.csv                           \b\b\b\b 11%\b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/35.csv                           \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/36.csv                           \b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/37.csv                           \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/38.csv                           \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/39.csv                           \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/4.csv                            \b\b\b\b 14%\b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/40.csv                           \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/41.csv                           \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/42.csv                           \b\b\b\b 15%\b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/43.csv                           \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/44.csv                           \b\b\b\b 16%\b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/45.csv                           \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/46.csv                           \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/47.csv                           \b\b\b\b 17%\b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/48.csv                           \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/49.csv                           \b\b\b\b 18%\b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/5.csv                            \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/50.csv                           \b\b\b\b 19%\b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/51.csv                           \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/52.csv                           \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/53.csv                           \b\b\b\b 20%\b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/54.csv                           \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/55.csv                           \b\b\b\b 21%\b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/56.csv                           \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/57.csv                           \b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/58.csv                           \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/59.csv                           \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/6.csv                            \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/60.csv                           \b\b\b\b 24%\b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/61.csv                           \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/62.csv                           \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/63.csv                           \b\b\b\b 25%\b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/64.csv                           \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/65.csv                           \b\b\b\b 26%\b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/66.csv                           \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/67.csv                           \b\b\b\b 27%\b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/68.csv                           \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/69.csv                           \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/7.csv                            \b\b\b\b 28%\b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/70.csv                           \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/71.csv                           \b\b\b\b 29%\b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/72.csv                           \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/73.csv                           \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/74.csv                           \b\b\b\b 30%\b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/75.csv                           \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/76.csv                           \b\b\b\b 31%\b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/77.csv                           \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/78.csv                           \b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/79.csv                           \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/8.csv                            \b\b\b\b 33%\b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/80.csv                           \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/81.csv                           \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/82.csv                           \b\b\b\b 34%\b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/83.csv                           \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/84.csv                           \b\b\b\b 35%\b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/85.csv                           \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/86.csv                           \b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/87.csv                           \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/88.csv                           \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/89.csv                           \b\b\b\b 37%\b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/9.csv                            \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/90.csv                           \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/91.csv                           \b\b\b\b 38%\b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/92.csv                           \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/93.csv                           \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/94.csv                           \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/95.csv                           \b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/96.csv                           \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/97.csv                           \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/98.csv                           \b\b\b\b 41%\b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/host logs/99.csv                           \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/NGIDS.pcap                                 \b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v1/Readme.txt                                 \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Creating    NGIDS/NGIDS-DS-v2                                         OK\n",
            "Extracting  NGIDS/NGIDS-DS-v2/readme.txt                                 \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Creating    NGIDS/NGIDS-DS-v2/Test data                               OK\n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_1.csv                          \b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_10.csv                         \b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_11.csv                         \b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_12.csv                         \b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_13.csv                         \b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_14.csv                         \b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_15.csv                         \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_16.csv                         \b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_2.csv                          \b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_3.csv                          \b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_4.csv                          \b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_5.csv                          \b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_6.csv                          \b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_7.csv                          \b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_8.csv                          \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Test data/0_9.csv                          \b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Creating    NGIDS/NGIDS-DS-v2/Traing data                             OK\n",
            "Extracting  NGIDS/NGIDS-DS-v2/Traing data/0_1.csv                        \b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Traing data/0_2.csv                        \b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Traing data/0_3.csv                        \b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/NGIDS-DS-v2/Traing data/0_4.csv                        \b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  NGIDS/Readme.txt                                             \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwtoL3AD2QIB",
        "outputId": "e72748cd-a9d4-4bb5-c7d8-16aed99205c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Host data processing"
      ],
      "metadata": {
        "id": "zJg_zDVfT9Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "RyP2JfTfXV2w",
        "outputId": "973538b7-05f1-4bcf-aa5f-5d4a630e7dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/NGIDS"
      ],
      "metadata": {
        "id": "yjJ1N5X8hknr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "UJ0W3F-qT6Td"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HostPreprocessing():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def __file_path_collection(self, folder_path, ends='.csv'):\n",
        "    try:\n",
        "      joined_list = []\n",
        "      for file_name in os.listdir(folder_path):\n",
        "        file_name = os.path.join(folder_path, file_name)\n",
        "        if os.path.isfile(file_name) and file_name.endswith(ends):\n",
        "          joined_list.append(file_name)\n",
        "      return joined_list\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def rename_columns(self, folder_path):\n",
        "    files = self.__file_path_collection(folder_path)\n",
        "    try:\n",
        "      for file in tqdm(files, desc=\"Renaming columns\") :\n",
        "        df = pd.read_csv(file)\n",
        "        column_name = df.columns.tolist()\n",
        "        df.rename(columns={\n",
        "            column_name[0]:'Date',\n",
        "            column_name[1]:'Time',\n",
        "            column_name[2]:'Unique_Identification',\n",
        "            column_name[3]:'Execution_Path',\n",
        "            column_name[4]:'System_Calls_Identifiers',\n",
        "            column_name[5]:\"Event's_Unique_Identification\",\n",
        "            column_name[6]:'attacks',\n",
        "            column_name[7]:\"Sub_Type_Attack\",\n",
        "            column_name[8]:\"Label\"\n",
        "            }, inplace=True)\n",
        "        df.to_csv(file, index=False)\n",
        "      return f\"done files...\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def data_encoding(self, folder_path, column_number : int):\n",
        "    files = self.__file_path_collection(folder_path)\n",
        "    encoder = LabelEncoder()\n",
        "    all_value = []\n",
        "    try:\n",
        "      for file in tqdm(files, desc=\"Extract all values from files\"):\n",
        "        df = pd.read_csv(file)\n",
        "        if column_number < df.shape[1]:\n",
        "                all_value.extend(df.iloc[:, column_number].dropna().unique())\n",
        "        else:\n",
        "            print(f\"❌ Skipped (no column {column_number}): {file}\")\n",
        "\n",
        "        #print( len(df.iloc[:, column_number].dropna().unique()) , file )\n",
        "      encoder.fit(all_value)\n",
        "\n",
        "      for file in tqdm(files, desc=\"encoder data\"):\n",
        "        df = pd.read_csv(file)\n",
        "        df.iloc[:, column_number] = encoder.transform(df.iloc[:, column_number])\n",
        "        #df.drop(columns=[df.columns[column_number]], inplace=True)\n",
        "        #print(len(df.iloc[:, column_number].dropna().unique()), df.iloc[:, column_number].dropna().unique(), file )\n",
        "        df.to_csv(file, index=False)\n",
        "      return f\"done file...\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def paths_encoding(self, folder_path, column_number: int):\n",
        "      files = self.__file_path_collection(folder_path)\n",
        "      parts_temp_file = \"/content/unique_parts_temp.txt\"\n",
        "\n",
        "      # احذف الملف المؤقت لو موجود من تشغيل سابق\n",
        "      if os.path.exists(parts_temp_file):\n",
        "          os.remove(parts_temp_file)\n",
        "\n",
        "      max_parts_len = 0\n",
        "\n",
        "      # المرحلة الأولى: جمع الأجزاء الفريدة وتخزينها في ملف نصي\n",
        "      for file in tqdm(files, desc=\"Collecting unique path parts\"):\n",
        "          for chunk in pd.read_csv(file, chunksize=10000, usecols=[column_number]):\n",
        "              paths = chunk.iloc[:, 0].dropna().map(str)\n",
        "\n",
        "              with open(parts_temp_file, \"a\", encoding=\"utf-8\") as f:  # فتح الملف في وضع الإلحاق append\n",
        "                  for path in paths:\n",
        "                      path = path.strip(\"/\")\n",
        "                      if not path:\n",
        "                          continue\n",
        "\n",
        "                      parts = path.split(\"/\")\n",
        "                      f.write(\"\\n\".join(parts) + \"\\n\")  # كتابة كل جزء في سطر منفصل\n",
        "\n",
        "                      if len(parts) > max_parts_len:\n",
        "                          max_parts_len = len(parts)\n",
        "\n",
        "      # بعد انتهاء الجمع: قراءة الملف واستخراج الأجزاء الفريدة\n",
        "      with open(parts_temp_file, \"r\", encoding=\"utf-8\") as f:\n",
        "          all_parts = f.read().splitlines()\n",
        "\n",
        "      unique_parts = sorted(set(all_parts))\n",
        "      part_to_index = {part: idx for idx, part in enumerate(unique_parts)}\n",
        "\n",
        "      # المرحلة الثانية: ترميز المسارات وحفظ الملفات\n",
        "      for file in tqdm(files, desc=\"Encoding and saving data\"):\n",
        "          all_chunks = []\n",
        "\n",
        "          for chunk in pd.read_csv(file, chunksize=10000):\n",
        "              paths = chunk.iloc[:, column_number].fillna(\"\").map(str)\n",
        "\n",
        "              encoded_matrix = np.full((len(paths), max_parts_len), -1, dtype=int)\n",
        "              for i, path in enumerate(paths):\n",
        "                  path = path.strip(\"/\")\n",
        "                  parts = path.split(\"/\") if path else []\n",
        "                  encoded = [part_to_index.get(part, -1) for part in parts]\n",
        "                  encoded_matrix[i, :len(encoded)] = encoded\n",
        "\n",
        "              encoded_df = pd.DataFrame(encoded_matrix, index=chunk.index,\n",
        "                                        columns=[f\"path_part_{i+1}\" for i in range(max_parts_len)])\n",
        "              chunk.drop(chunk.columns[column_number], axis=1, inplace=True)\n",
        "\n",
        "              final_df = pd.concat([chunk.reset_index(drop=True), encoded_df], axis=1)\n",
        "              all_chunks.append(final_df)\n",
        "\n",
        "          pd.concat(all_chunks, ignore_index=True).to_csv(file, index=False)\n",
        "\n",
        "      # حذف الملف المؤقت بعد الانتهاء\n",
        "      os.remove(parts_temp_file)\n",
        "\n",
        "      return \"✅ Path encoding and file saving completed successfully.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def extract_datetime_features(self, folder_path, date_col, time_col ):\n",
        "    files = self.__file_path_collection(folder_path) # Assign the output of __file_path_collection to files\n",
        "    try:\n",
        "      for file in tqdm(files, desc=\"read all files\"): # Iterate through the 'files' list, not 'file_paths'\n",
        "        df = pd.read_csv(file) # Read each file into a DataFrame\n",
        "        if date_col in df.columns and time_col in df.columns :\n",
        "          df[date_col] = pd.to_datetime(df[date_col], format='%d/%m/%Y', errors='coerce', dayfirst=True)\n",
        "\n",
        "          df['year'] = df[date_col].dt.year\n",
        "          df['month'] = df[date_col].dt.month\n",
        "          df['day'] = df[date_col].dt.day\n",
        "\n",
        "          # Assuming 'Time' column is string and needs to be converted to datetime\n",
        "          df[time_col] = pd.to_datetime(df[time_col], format='%H:%M:%S', errors='coerce', dayfirst=True)\n",
        "\n",
        "          df['hour'] = df[time_col].dt.hour\n",
        "          df['minute'] = df[time_col].dt.minute\n",
        "          df['second'] = df[time_col].dt.second\n",
        "\n",
        "          df.drop(columns=[date_col, time_col], inplace=True)\n",
        "\n",
        "          df.to_csv(file, index=False) # Save changes back to the original file\n",
        "          print(f\"✅ Processed: {df.head(3)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in {file}: {e}\") # Print the error and the file name\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def file_collection(self, folder_path):\n",
        "    try:\n",
        "      file_paths = self.__file_path_collection(folder_path)\n",
        "      if file_paths:\n",
        "        output_folder = os.path.join(os.getcwd(),'files')\n",
        "        os.makedirs(output_folder ,exist_ok=True)\n",
        "        output_file = os.path.join(output_folder,\"final.csv\")\n",
        "\n",
        "        for file in tqdm(file_paths, desc=\"read all files\"):\n",
        "\n",
        "          first = True\n",
        "          chunk = pd.read_csv(file, chunksize=10000)\n",
        "          for part in chunk:\n",
        "            part.to_csv(output_file, mode='a', header=first, index=False)\n",
        "            first = False\n",
        "\n",
        "      return  f\"done file...\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "a = HostPreprocessing()\n",
        "#a.file_path_collection(\"/content/NGIDS/NGIDS-DS-v1/host logs\")\n",
        "a.file_collection(\"/content/host logs\")\n",
        "#a.rename_columns( '/content/NGIDS/NGIDS-DS-v1/host logs')\n",
        "#a.data_encoding('/content/NGIDS/NGIDS-DS-v1/host logs', column_number=6)\n",
        "#a.data_encoding('/content/NGIDS/NGIDS-DS-v1/host logs', column_number=7)\n",
        "\n",
        "#c=a.paths_encoding('/content/NGIDS/NGIDS-DS-v1/host logs', column_number=3)\n",
        "\n",
        "#a.extract_datetime_features(  folder_path='/content/NGIDS/NGIDS-DS-v1/host logs'\n",
        "#                           ,date_col='Date',\n",
        " #                           time_col='Time' )\n",
        "#a.delete_data( folder_path='/content/NGIDS/NGIDS-DS-v1/host logs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "iadsIYxGUDEL",
        "outputId": "d92a9051-0c78-418e-d1ee-e810c59449c0",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "read all files: 100%|██████████| 99/99 [13:36<00:00,  8.24s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'done file...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def delete_data(file_path):\n",
        "    try:\n",
        "        # استخدام chunksize لتحميل البيانات بشكل جزئي\n",
        "        chunksize = 100000  # يمكنك تعديل الحجم حسب الذاكرة المتاحة\n",
        "        writer = None  # لكتابة البيانات المعدلة\n",
        "\n",
        "        for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
        "            # حذف الأعمدة التي تحتوي على قيمة واحدة فقط\n",
        "            chunk = chunk.loc[:, chunk.nunique() > 1]\n",
        "\n",
        "            # إذا كانت هذه هي أول شريحة من البيانات، اكتب العنوان\n",
        "            if writer is None:\n",
        "                chunk.to_csv(file_path, index=False, mode='w')  # الكتابة لأول مرة مع الحفظ\n",
        "                writer = True\n",
        "            else:\n",
        "                # إضافة الشريحة المعدلة إلى الملف\n",
        "                chunk.to_csv(file_path, index=False, header=False, mode='a')  # الكتابة بإضافة البيانات\n",
        "\n",
        "        return \"Columns containing only one value are deleted...\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# مسار الملف الذي تريد معالجته\n",
        "file_path = '/content/files/final.csv'\n",
        "print(delete_data(file_path))"
      ],
      "metadata": {
        "id": "PmShO2ibcK2H",
        "outputId": "d5fc140a-1670-4e9f-ad7e-634c04aa0efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns containing only one value are deleted...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# اسم المجلد الذي يحتوي على ملفات CSV\n",
        "folder_path = '/content/host logs'\n",
        "\n",
        "# اسم العمود الذي تريد حذفه\n",
        "column_to_delete = 'Execution_Path'\n",
        "\n",
        "# الحصول على قائمة بكل ملفات CSV\n",
        "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# استخدام tqdm مع اللوب\n",
        "for filename in tqdm(csv_files, desc=\"معالجة الملفات\"):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if column_to_delete in df.columns:\n",
        "            df.drop(columns=[column_to_delete], inplace=True)\n",
        "            df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        print(f\"حدث خطأ مع الملف {filename}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuHwWTf8Jh4p",
        "outputId": "23760e8b-7288-4956-b426-2a33ff33c483"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "معالجة الملفات: 100%|██████████| 99/99 [13:52<00:00,  8.41s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file = '/content/files/final.csv'\n",
        "\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "df.info()\n",
        "df.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7u3D4T--XQ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/host logs\" \"/content/drive/MyDrive/hybrid_IDS/dataset/all/\""
      ],
      "metadata": {
        "id": "Lvhaii6LdcUT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/files/final.csv /content/drive/MyDrive/hybrid_IDS/dataset/all/"
      ],
      "metadata": {
        "id": "fFOt4NgEXZC_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# اعدادات\n",
        "folder_path = '/content/host logs'  # ضع مسار المجلد هنا\n",
        "path_column = 'Execution_Path'                 # اسم العمود الذي يحتوي المسارات\n",
        "encoding = 'utf-8'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# جلب أسماء كل ملفات csv\n",
        "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# الخطوة ١: بناء القاموس واكتشاف أقصى عمق للمسارات\n",
        "unique_parts = set()\n",
        "max_depth = 0\n",
        "\n",
        "print(\"المرحلة ١/٢: بناء القاموس واكتشاف العمق...\")\n",
        "for filename in tqdm(csv_files, desc=\"بناء القاموس\"):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    for chunk in pd.read_csv(file_path, usecols=[path_column], chunksize=10000, encoding=encoding):\n",
        "        paths = chunk[path_column].dropna()\n",
        "        for path in paths:\n",
        "            parts = str(path).split('/')\n",
        "            parts = [p for p in parts if p]\n",
        "            unique_parts.update(parts)\n",
        "            max_depth = max(max_depth, len(parts))\n",
        "\n",
        "# إنشاء القاموس\n",
        "encoder = {part: idx for idx, part in enumerate(sorted(unique_parts))}\n",
        "\n",
        "print(f\"عدد الأجزاء الفريدة: {len(encoder)}\")\n",
        "print(f\"أقصى عمق مسار: {max_depth}\")\n",
        "\n",
        "# الخطوة ٢: معالجة كل ملف مع دمج النتائج\n",
        "print(\"\\nالمرحلة ٢/٢: معالجة الملفات ودمج النتائج...\")\n",
        "for filename in tqdm(csv_files, desc=\"معالجة الملفات\"):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    new_chunks = []\n",
        "\n",
        "    for chunk in pd.read_csv(file_path, chunksize=10000, encoding=encoding):\n",
        "        if path_column not in chunk.columns:\n",
        "            continue\n",
        "\n",
        "        encoded_columns = []\n",
        "\n",
        "        for path in chunk[path_column].fillna(''):\n",
        "            parts = str(path).split('/')\n",
        "            parts = [p for p in parts if p]\n",
        "            encoded_parts = [encoder.get(part, np.nan) for part in parts]\n",
        "            while len(encoded_parts) < max_depth:\n",
        "                encoded_parts.append(np.nan)\n",
        "            encoded_columns.append(encoded_parts)\n",
        "\n",
        "        # تحويل القيم المشفرة إلى DataFrame مع أسماء أعمدة محسنة\n",
        "        encoded_df = pd.DataFrame(\n",
        "            encoded_columns,\n",
        "            columns=[f\"{path_column}_part_{i}\" for i in range(max_depth)]\n",
        "        )\n",
        "\n",
        "        # دمج البيانات الأصلية مع البيانات المشفرة\n",
        "        combined_chunk = pd.concat([chunk.reset_index(drop=True), encoded_df], axis=1)\n",
        "        new_chunks.append(combined_chunk)\n",
        "\n",
        "    # دمج جميع الـ chunks مع بعض\n",
        "    final_df = pd.concat(new_chunks, ignore_index=True)\n",
        "\n",
        "    # حفظ الملف النهائي\n",
        "    new_file_path = os.path.join(folder_path, filename)\n",
        "    final_df.to_csv(new_file_path, index=False, encoding=encoding)\n",
        "\n",
        "print(\"\\n✅ تم الانتهاء من دمج البيانات وحفظ جميع الملفات.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPyols9e6hMs",
        "outputId": "da12c64b-f161-4a91-f381-7f38d285a6a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "المرحلة ١/٢: بناء القاموس واكتشاف العمق...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "بناء القاموس: 100%|██████████| 99/99 [03:56<00:00,  2.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "عدد الأجزاء الفريدة: 134\n",
            "أقصى عمق مسار: 5\n",
            "\n",
            "المرحلة ٢/٢: معالجة الملفات ودمج النتائج...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "معالجة الملفات: 100%|██████████| 99/99 [22:29<00:00, 13.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ تم الانتهاء من دمج البيانات وحفظ جميع الملفات.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/host logs\""
      ],
      "metadata": {
        "id": "x8AA6SaonWm0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_with_target = numeric_df.corr()[target_col].drop(target_col).sort_values(ascending=False)\n",
        "correlation_with_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "TnUgJlQ0hKWG",
        "outputId": "83c903be-c4dd-4e39-c3b7-38b0d99a26fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "path_part_4                      0.259518\n",
              "path_part_5                      0.128456\n",
              "path_part_2                      0.122674\n",
              "hour                             0.010651\n",
              "path_part_1                      0.008840\n",
              "Event's_Unique_Identification    0.005089\n",
              "Unique_Identification            0.002967\n",
              "second                           0.001407\n",
              "System_Calls_Identifiers        -0.001347\n",
              "minute                          -0.011156\n",
              "path_part_3                     -0.100076\n",
              "Sub_Type_Attack                 -0.868641\n",
              "attacks                         -0.983979\n",
              "Name: Label, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>path_part_4</th>\n",
              "      <td>0.259518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>path_part_5</th>\n",
              "      <td>0.128456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>path_part_2</th>\n",
              "      <td>0.122674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hour</th>\n",
              "      <td>0.010651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>path_part_1</th>\n",
              "      <td>0.008840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Event's_Unique_Identification</th>\n",
              "      <td>0.005089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique_Identification</th>\n",
              "      <td>0.002967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>second</th>\n",
              "      <td>0.001407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>System_Calls_Identifiers</th>\n",
              "      <td>-0.001347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minute</th>\n",
              "      <td>-0.011156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>path_part_3</th>\n",
              "      <td>-0.100076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sub_Type_Attack</th>\n",
              "      <td>-0.868641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attacks</th>\n",
              "      <td>-0.983979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file = '/content/files/final.csv'\n",
        "# Load the data\n",
        "chunk_size = 10000  # عدد الصفوف بالدفعة\n",
        "chunks = pd.read_csv(file, chunksize=chunk_size)\n",
        "\n",
        "for chunk in chunks:\n",
        "    print(chunk.info())\n",
        "    print (chunk.head())\n",
        "    break  # فقط لعرض أول دفعة كمثال"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkA_iFJnU5UY",
        "outputId": "fc29c26b-c7cb-48b9-cb0a-ac7cede9146b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Unique_Identification          10000 non-null  int64  \n",
            " 1   System_Calls_Identifiers       10000 non-null  int64  \n",
            " 2   Event's_Unique_Identification  10000 non-null  int64  \n",
            " 3   attacks                        10000 non-null  int64  \n",
            " 4   Sub_Type_Attack                10000 non-null  int64  \n",
            " 5   Label                          10000 non-null  int64  \n",
            " 6   hour                           10000 non-null  int64  \n",
            " 7   minute                         10000 non-null  int64  \n",
            " 8   second                         10000 non-null  int64  \n",
            " 9   Execution_Path_part_0          10000 non-null  int64  \n",
            " 10  Execution_Path_part_1          10000 non-null  int64  \n",
            " 11  Execution_Path_part_2          9908 non-null   float64\n",
            " 12  Execution_Path_part_3          1136 non-null   float64\n",
            " 13  Execution_Path_part_4          310 non-null    float64\n",
            "dtypes: float64(3), int64(11)\n",
            "memory usage: 1.1 MB\n",
            "None\n",
            "   Unique_Identification  System_Calls_Identifiers  \\\n",
            "0                   1834                       168   \n",
            "1                  16516                       168   \n",
            "2                   2114                       168   \n",
            "3                   2133                       168   \n",
            "4                   2318                       168   \n",
            "\n",
            "   Event's_Unique_Identification  attacks  Sub_Type_Attack  Label  hour  \\\n",
            "0                       86128462        7               52      0    10   \n",
            "1                       86101141        7               52      0    10   \n",
            "2                       86101227        7               52      0    10   \n",
            "3                       86102461        7               52      0    10   \n",
            "4                       86097850        7               52      0    10   \n",
            "\n",
            "   minute  second  Execution_Path_part_0  Execution_Path_part_1  \\\n",
            "0       8      44                    128                     16   \n",
            "1      10       0                    128                     79   \n",
            "2      10       0                    128                     16   \n",
            "3      10       4                    128                     79   \n",
            "4      10      34                    128                     16   \n",
            "\n",
            "   Execution_Path_part_2  Execution_Path_part_3  Execution_Path_part_4  \n",
            "0                   57.0                    NaN                    NaN  \n",
            "1                  113.0                  117.0                    NaN  \n",
            "2                   21.0                    NaN                    NaN  \n",
            "3                   55.0                   41.0                   42.0  \n",
            "4                  132.0                    NaN                    NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file = '/content/files/final.csv'\n",
        "\n",
        "# الحصول على حجم الملف بالبايت\n",
        "file_size = os.path.getsize(file)\n",
        "\n",
        "# تحويل الحجم إلى ميجابايت\n",
        "file_size_mb = file_size / (1024 * 1024)\n",
        "\n",
        "print(f\"حجم الملف: {file_size_mb:.2f} ميجابايت\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3cNsgvfXOdR",
        "outputId": "234574df-8035-4fe8-d626-be98ef4bd54c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "حجم الملف: 4.80 ميجابايت\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['year'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "gZ5LeI5wU4ft",
        "outputId": "cde89f40-1be8-4a4f-9a43-6102728fed37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "year\n",
              "2016.0    1000000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016.0</th>\n",
              "      <td>1000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/NGIDS/NGIDS-DS-v1/host logs/10_encoded.csv'\n",
        "df = pd.read_csv(file)\n",
        "df.info()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "UeD8kcuSskXq",
        "outputId": "61880d87-4349-473d-f728-955ef2a976b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1990000 entries, 0 to 1989999\n",
            "Data columns (total 17 columns):\n",
            " #   Column                         Dtype  \n",
            "---  ------                         -----  \n",
            " 0   Unique_Identification          float64\n",
            " 1   System_Calls_Identifiers       float64\n",
            " 2   Event's_Unique_Identification  float64\n",
            " 3   attacks                        float64\n",
            " 4   Sub_Type_Attack                float64\n",
            " 5   Label                          float64\n",
            " 6   path_part_1                    float64\n",
            " 7   path_part_2                    float64\n",
            " 8   path_part_3                    float64\n",
            " 9   path_part_4                    float64\n",
            " 10  path_part_5                    float64\n",
            " 11  year                           float64\n",
            " 12  month                          float64\n",
            " 13  day                            float64\n",
            " 14  hour                           float64\n",
            " 15  minute                         float64\n",
            " 16  second                         float64\n",
            "dtypes: float64(17)\n",
            "memory usage: 258.1 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unique_Identification  System_Calls_Identifiers  \\\n",
              "0                 2111.0                     168.0   \n",
              "1                 2318.0                     168.0   \n",
              "2                 4493.0                      78.0   \n",
              "3                 4493.0                      78.0   \n",
              "4                 4519.0                      78.0   \n",
              "\n",
              "   Event's_Unique_Identification  attacks  Sub_Type_Attack  Label  \\\n",
              "0                      8441500.0      7.0             52.0    0.0   \n",
              "1                      8441325.0      7.0             52.0    0.0   \n",
              "2                      8440867.0      7.0             52.0    0.0   \n",
              "3                      8440875.0      7.0             52.0    0.0   \n",
              "4                      8440865.0      7.0             52.0    0.0   \n",
              "\n",
              "   path_part_1  path_part_2  path_part_3  path_part_4  path_part_5    year  \\\n",
              "0        102.0         87.0         76.0         -1.0         -1.0  2016.0   \n",
              "1        102.0         87.0         49.0         -1.0         -1.0  2016.0   \n",
              "2        102.0        104.0         60.0         -1.0         -1.0  2016.0   \n",
              "3        102.0        104.0         60.0         -1.0         -1.0  2016.0   \n",
              "4        102.0        104.0         60.0         -1.0         -1.0  2016.0   \n",
              "\n",
              "   month   day  hour  minute  second  \n",
              "0    3.0  11.0  16.0    25.0    47.0  \n",
              "1    3.0  11.0  16.0    25.0    47.0  \n",
              "2    3.0  11.0  16.0    25.0    49.0  \n",
              "3    3.0  11.0  16.0    25.0    49.0  \n",
              "4    3.0  11.0  16.0    25.0    49.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-650d268a-4051-47b0-a679-23dd96b32bc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_Identification</th>\n",
              "      <th>System_Calls_Identifiers</th>\n",
              "      <th>Event's_Unique_Identification</th>\n",
              "      <th>attacks</th>\n",
              "      <th>Sub_Type_Attack</th>\n",
              "      <th>Label</th>\n",
              "      <th>path_part_1</th>\n",
              "      <th>path_part_2</th>\n",
              "      <th>path_part_3</th>\n",
              "      <th>path_part_4</th>\n",
              "      <th>path_part_5</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2111.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>8441500.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2318.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>8441325.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4493.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>8440867.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4493.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>8440875.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4519.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>8440865.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-650d268a-4051-47b0-a679-23dd96b32bc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-650d268a-4051-47b0-a679-23dd96b32bc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-650d268a-4051-47b0-a679-23dd96b32bc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f951e6e1-3d6a-4be5-a7f8-84525a447ae3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f951e6e1-3d6a-4be5-a7f8-84525a447ae3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f951e6e1-3d6a-4be5-a7f8-84525a447ae3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/NGIDS/NGIDS-DS-v1/host logs/21_encoded.csv')\n",
        "df['Time'].value_counts() # Changed 'vaule_counts()' to 'value_counts()'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "pL2jMyxxFubh",
        "outputId": "5289433e-a46a-4af5-a39a-0b4f187ee39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time\n",
              "6:00:00    748\n",
              "5:46:00    622\n",
              "5:57:00    585\n",
              "5:48:00    551\n",
              "5:52:00    541\n",
              "          ... \n",
              "4:42:00      1\n",
              "4:24:15      1\n",
              "4:24:00      1\n",
              "5:31:07      1\n",
              "5:31:22      1\n",
              "Name: count, Length: 5291, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6:00:00</th>\n",
              "      <td>748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5:46:00</th>\n",
              "      <td>622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5:57:00</th>\n",
              "      <td>585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5:48:00</th>\n",
              "      <td>551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5:52:00</th>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4:42:00</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4:24:15</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4:24:00</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5:31:07</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5:31:22</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5291 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#network\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yP5t2mKKWsNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scapy"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4kD82xplN91",
        "outputId": "1b79c674-9fb5-4563-d4e8-4c0f88f014c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scapy\n",
            "  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scapy\n",
            "Successfully installed scapy-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from scapy.all import PcapReader"
      ],
      "metadata": {
        "id": "7EZjcRDSWvNI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetworkPreprocessing:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "  def extract_tcp_option(self, option, key):\n",
        "    for opt in option:\n",
        "      if opt[0] == key:\n",
        "        return opt[1]\n",
        "    return None\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "  def convert_pcap_csv(self, pcap_file, csv_file):\n",
        "    try:\n",
        "      print(\"Countig packages...\")\n",
        "      with PcapReader(pcap_file) as count_reader:\n",
        "        total_packets = sum(1 for _ in count_reader)\n",
        "        print(f\"Total number of packages: {total_packets}\")\n",
        "\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with PcapReader(pcap_file) as packets:\n",
        "        with open(csv_file, mode='w', newline=\"\") as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([\n",
        "              \"Packet Number\", \"Ethernet DST\", \"Ethernet SRC\", \"Ethernet Type\",\n",
        "              \"IP Version\", \"IP IHL\", \"IP TOS\", \"IP Length\", \"IP ID\", \"IP Flags\",\n",
        "              \"IP Fragmentation\", \"IP TTL\", \"IP Proto\", \"IP Checksum\",\n",
        "              \"IP Src\", \"IP Dst\", \"TCP Src Port\", \"TCP Dst Port\", \"TCP Seq\",\n",
        "              \"TCP Ack\", \"TCP Data Offset\", \"TCP Reserved\", \"TCP Flags\",\n",
        "              \"TCP Window\", \"TCP Checksum\", \"TCP Urgent Pointer\", \"TCP Options MSS\",\n",
        "              \"TCP Options WScale\", \"TCP Options NOP\",\"Hexdump\"\n",
        "          ])\n",
        "\n",
        "          for i, packet in enumerate(tqdm(packets,total=total_packets, desc=\"Packet processing\")):\n",
        "            if packet.haslayer('Ethernet'):\n",
        "              eth_dst = packet['Ethernet'].dst\n",
        "              eth_src = packet['Ethernet'].src\n",
        "              eth_type = packet['Ethernet'].type\n",
        "            else:\n",
        "              eth_dst = eth_src = eth_type = None\n",
        "\n",
        "            if packet.haslayer('IP'):\n",
        "              ip_version = packet['IP'].version\n",
        "              ip_ihl = packet['IP'].ihl\n",
        "              ip_tos = packet['IP'].tos\n",
        "              ip_len = packet['IP'].len\n",
        "              ip_id = packet['IP'].id\n",
        "              ip_flags = packet['IP'].flags\n",
        "              ip_frag = packet['IP'].frag\n",
        "              ip_ttl = packet['IP'].ttl\n",
        "              ip_proto = packet['IP'].proto\n",
        "              ip_chksum = packet['IP'].chksum\n",
        "              ip_src = packet['IP'].src\n",
        "              ip_dst = packet['IP'].dst\n",
        "            else:\n",
        "              ip_version = ip_ihl = ip_tos = ip_len = ip_id = ip_flags = ip_frag = ip_ttl = ip_proto = ip_chksum = ip_src = ip_dst = None\n",
        "\n",
        "            if packet.haslayer('TCP'):\n",
        "              tcp_sport = packet['TCP'].sport\n",
        "              tcp_dport = packet['TCP'].dport\n",
        "              tcp_seq = packet['TCP'].seq\n",
        "              tcp_ack = packet['TCP'].ack\n",
        "              tcp_dataofs = packet['TCP'].dataofs\n",
        "              tcp_reserved = packet['TCP'].reserved\n",
        "              tcp_flags = packet['TCP'].flags\n",
        "              tcp_window = packet['TCP'].window\n",
        "              tcp_chksum = packet['TCP'].chksum\n",
        "              tcp_urgptr = packet['TCP'].urgptr\n",
        "              tcp_options = packet['TCP'].options\n",
        "\n",
        "              tcp_mss = self.extract_tcp_option(tcp_options, 'MSS')\n",
        "              tcp_wscale = self.extract_tcp_option(tcp_options, 'WScale')\n",
        "              tcp_nop_count = self.extract_tcp_option(tcp_options, 'NOP')\n",
        "\n",
        "            else:\n",
        "              tcp_sport = tcp_dport = tcp_seq = tcp_ack = tcp_dataofs = tcp_reserved = tcp_flags = tcp_window = tcp_chksum = tcp_urgptr = tcp_mss = tcp_wscale = tcp_nop_count = None\n",
        "\n",
        "            raw_data = packet.original.hex()\n",
        "            writer.writerow([\n",
        "                i + 1, eth_dst, eth_src, eth_type,\n",
        "                  ip_version, ip_ihl, ip_tos, ip_len, ip_id, ip_flags,\n",
        "                  ip_frag, ip_ttl, ip_proto, ip_chksum,\n",
        "                  ip_src, ip_dst, tcp_sport, tcp_dport, tcp_seq,\n",
        "                  tcp_ack, tcp_dataofs, tcp_reserved, tcp_flags,\n",
        "                  tcp_window, tcp_chksum, tcp_urgptr, tcp_mss, tcp_wscale, tcp_nop_count,\n",
        "                  raw_data\n",
        "            ])\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "a = NetworkPreprocessing()\n",
        "#a.convert_pcap_csv(pcap_file='/content/NGIDS/NGIDS-DS-v1/NGIDS.pcap',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/network.csv')\n",
        "#a.delete_data(file_path='/content/drive/MyDrive/hybrid_IDS/network.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bJW0krgnXThk",
        "outputId": "c6ab4c5e-07c8-46cd-a10f-263ed88555ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Columns containing only one value are deleted...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PcapFileProcessing:\n",
        "  def __init__(self) -> None:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "\n",
        "  def date_time_columns(self, file_path, csv_file):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, dtype=str)\n",
        "        df.columns = df.columns.str.strip()\n",
        "        if 'timestamp' not in df.columns:\n",
        "            return \"Error: The 'timestamp' column is missing from the file.\"\n",
        "\n",
        "        df['timestamp'] = df['timestamp'].astype(str).str.strip()\n",
        "\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', dayfirst=True)\n",
        "\n",
        "        if df['timestamp'].isnull().all():\n",
        "            return \"All values in 'timestamp' are invalid and could not be converted.\"\n",
        "\n",
        "        # Extract date and time\n",
        "        df['date'] = df['timestamp'].dt.strftime('%d/%m/%Y')\n",
        "        df['time'] = df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "        # Save the result\n",
        "        df.to_csv(csv_file, index=False)\n",
        "\n",
        "        return \"Successfully converted 'timestamp' to 'date' and 'time'.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during conversion: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def convert_log_csv(self, log_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with open(log_file, \"r\") as logfile:\n",
        "        log_data = logfile.read()\n",
        "      pattern = re.compile(\n",
        "          r'(?P<timestamp>\\d{2}/\\d{2}/\\d{4}-\\d{2}:\\d{2}:\\d{2}\\.\\d+)\\s+\\[\\*\\*\\]\\s+\\[(?P<sid>[^]]+)\\]\\s+(?P<signature>.*?)\\s+\\[\\*\\*\\]\\s+\\[Classification:\\s+(?P<classification>.*?)\\]\\s+\\[Priority:\\s+(?P<priority>\\d+)\\]\\s+\\{(?P<protocol>\\w+)\\}\\s+(?P<src_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<src_port>\\d+)\\s+->\\s+(?P<dst_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<dst_port>\\d+)'\n",
        "          )\n",
        "      with open(csv_file, \"w\", newline=\"\") as csvfile:\n",
        "        fieldnames = ['timestamp', 'sid', 'signature', 'classification',\n",
        "                      'priority', 'protocol','src_ip', 'src_port', 'dst_ip', 'dst_port']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for match in pattern.finditer(log_data):\n",
        "          writer.writerow(match.groupdict())\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def convert_json_csv(self, json_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting JSON to CSV...\")\n",
        "      with open(json_file, 'r') as f:\n",
        "        data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "      fieldnames = set()\n",
        "      for row in data:\n",
        "          fieldnames.update(row.keys())\n",
        "\n",
        "      fieldnames = list(fieldnames)\n",
        "\n",
        "      with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(fieldnames)\n",
        "\n",
        "        for row in data:\n",
        "          writer.writerow(row.get(field, '') for field in fieldnames)\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "a = PcapFileProcessing()\n",
        "#a.convert_log_csv( log_file=\"/content/drive/MyDrive/hybrid_IDS/fast.log\",\n",
        "#                  csv_file=\"/content/drive/MyDrive/hybrid_IDS/alerts.csv\")\n",
        "\n",
        "#a.convert_json_csv(json_file='/content/drive/MyDrive/hybrid_IDS/eve.json',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "\n",
        "#a.delete_data( file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "a.date_time_columns(file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv',\n",
        "                    csv_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s_LHnGmW20vr",
        "outputId": "9b5a8e67-06a8-4cbb-af83-2173bbed7543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'تم تحويل timestamp بنجاح إلى date و time.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}