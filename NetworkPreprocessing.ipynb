{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hananbahtiti/Hybrid-Intrusion-detection-Systems/blob/main/NetworkPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NFX9RSeDfiVY",
        "outputId": "046d4fa0-837e-4861-e747-0b2dbf8dc3d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scapy\n",
            "  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scapy\n",
            "Successfully installed scapy-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scapy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/eve_del.csv /content/drive/MyDrive/hybrid_IDS/dataset/"
      ],
      "metadata": {
        "id": "LBZjWIJjDPvx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NSXj-h-NqUET",
        "outputId": "70edd18f-18b7-4cb4-aeb3-e6a7a18b5e67",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 286150 entries, 0 to 286149\n",
            "Series name: alert\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "5100 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 2.2+ MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9742c755c1c7>:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alert\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2010937, 'rev': 3, 'signature': 'ET SCAN Suspicious inbound to mySQL port 3306', 'category': 'Potentially Bad Traffic', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                                 1992\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2010935, 'rev': 3, 'signature': 'ET SCAN Suspicious inbound to MSSQL port 1433', 'category': 'Potentially Bad Traffic', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                                  595\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2002992, 'rev': 7, 'signature': 'ET SCAN Rapid POP3 Connections - Possible Brute Force Attack', 'category': 'Misc activity', 'severity': 3, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                             447\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2002994, 'rev': 7, 'signature': 'ET SCAN Rapid IMAP Connections - Possible Brute Force Attack', 'category': 'Misc activity', 'severity': 3, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                             363\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2010939, 'rev': 3, 'signature': 'ET SCAN Suspicious inbound to PostgreSQL port 5432', 'category': 'Potentially Bad Traffic', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                             300\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2200075, 'rev': 2, 'signature': 'SURICATA UDPv4 invalid checksum', 'category': 'Generic Protocol Command Decode', 'severity': 3}                                                                                                                                                                                                                                                                                                                                     241\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2200074, 'rev': 2, 'signature': 'SURICATA TCPv4 invalid checksum', 'category': 'Generic Protocol Command Decode', 'severity': 3}                                                                                                                                                                                                                                                                                                                                     200\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2032326, 'rev': 2, 'signature': 'ET EXPLOIT DD-WRT UPNP Unauthenticated Buffer Overflow (CVE-2021-27137)', 'category': 'Attempted Administrator Privilege Gain', 'severity': 1, 'metadata': {'attack_target': ['Networking_Equipment'], 'confidence': ['High'], 'created_at': ['2021_03_25'], 'cve': ['CVE_2021_27137'], 'deployment': ['Internal', 'Perimeter'], 'performance_impact': ['Low'], 'signature_severity': ['Major'], 'updated_at': ['2024_03_08']}}     116\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2200036, 'rev': 2, 'signature': 'SURICATA TCP option invalid length', 'category': 'Generic Protocol Command Decode', 'severity': 3}                                                                                                                                                                                                                                                                                                                                  100\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2200035, 'rev': 2, 'signature': 'SURICATA TCP invalid option length', 'category': 'Generic Protocol Command Decode', 'severity': 3}                                                                                                                                                                                                                                                                                                                                  100\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2102003, 'rev': 9, 'signature': 'GPL SQL Slammer Worm propagation attempt', 'category': 'Misc Attack', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_09_23'], 'cve': ['CVE_2002_0649'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                         100\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2012317, 'rev': 2, 'signature': 'ET NETBIOS Microsoft Windows Server 2003 Active Directory Pre-Auth BROWSER ELECTION Heap Overflow Attempt', 'category': 'Attempted Administrator Privilege Gain', 'severity': 1, 'metadata': {'confidence': ['Low'], 'created_at': ['2011_02_18'], 'signature_severity': ['Major'], 'updated_at': ['2019_07_26']}}                                                                                                                  100\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2200004, 'rev': 2, 'signature': 'SURICATA IPv4 invalid option', 'category': 'Generic Protocol Command Decode', 'severity': 3}                                                                                                                                                                                                                                                                                                                                        100\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2200008, 'rev': 2, 'signature': 'SURICATA IPv4 option end of list required', 'category': 'Generic Protocol Command Decode', 'severity': 3}                                                                                                                                                                                                                                                                                                                           100\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2101948, 'rev': 8, 'signature': 'GPL DNS zone transfer UDP', 'category': 'Attempted Information Leak', 'severity': 2, 'metadata': {'created_at': ['2010_09_23'], 'cve': ['CVE_1999_0532'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                                                   100\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2101411, 'rev': 13, 'signature': 'GPL SNMP public access udp', 'category': 'Attempted Information Leak', 'severity': 2, 'metadata': {'created_at': ['2010_09_23'], 'cve': ['CVE_1999_0517'], 'signature_severity': ['Informational'], 'updated_at': ['2019_10_08']}}                                                                                                                                                                                                  95\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2101384, 'rev': 9, 'signature': 'GPL MISC UPnP malformed advertisement', 'category': 'Misc Attack', 'severity': 2, 'metadata': {'created_at': ['2010_09_23'], 'cve': ['CVE_2001_0876'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                                                       50\n",
              "{'action': 'allowed', 'gid': 1, 'signature_id': 2002910, 'rev': 6, 'signature': 'ET SCAN Potential VNC Scan 5800-5820', 'category': 'Attempted Information Leak', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}                                                                                                                                                                                          1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alert</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2010937, 'rev': 3, 'signature': 'ET SCAN Suspicious inbound to mySQL port 3306', 'category': 'Potentially Bad Traffic', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>1992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2010935, 'rev': 3, 'signature': 'ET SCAN Suspicious inbound to MSSQL port 1433', 'category': 'Potentially Bad Traffic', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2002992, 'rev': 7, 'signature': 'ET SCAN Rapid POP3 Connections - Possible Brute Force Attack', 'category': 'Misc activity', 'severity': 3, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2002994, 'rev': 7, 'signature': 'ET SCAN Rapid IMAP Connections - Possible Brute Force Attack', 'category': 'Misc activity', 'severity': 3, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2010939, 'rev': 3, 'signature': 'ET SCAN Suspicious inbound to PostgreSQL port 5432', 'category': 'Potentially Bad Traffic', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2200075, 'rev': 2, 'signature': 'SURICATA UDPv4 invalid checksum', 'category': 'Generic Protocol Command Decode', 'severity': 3}</th>\n",
              "      <td>241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2200074, 'rev': 2, 'signature': 'SURICATA TCPv4 invalid checksum', 'category': 'Generic Protocol Command Decode', 'severity': 3}</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2032326, 'rev': 2, 'signature': 'ET EXPLOIT DD-WRT UPNP Unauthenticated Buffer Overflow (CVE-2021-27137)', 'category': 'Attempted Administrator Privilege Gain', 'severity': 1, 'metadata': {'attack_target': ['Networking_Equipment'], 'confidence': ['High'], 'created_at': ['2021_03_25'], 'cve': ['CVE_2021_27137'], 'deployment': ['Internal', 'Perimeter'], 'performance_impact': ['Low'], 'signature_severity': ['Major'], 'updated_at': ['2024_03_08']}}</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2200036, 'rev': 2, 'signature': 'SURICATA TCP option invalid length', 'category': 'Generic Protocol Command Decode', 'severity': 3}</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2200035, 'rev': 2, 'signature': 'SURICATA TCP invalid option length', 'category': 'Generic Protocol Command Decode', 'severity': 3}</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2102003, 'rev': 9, 'signature': 'GPL SQL Slammer Worm propagation attempt', 'category': 'Misc Attack', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_09_23'], 'cve': ['CVE_2002_0649'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2012317, 'rev': 2, 'signature': 'ET NETBIOS Microsoft Windows Server 2003 Active Directory Pre-Auth BROWSER ELECTION Heap Overflow Attempt', 'category': 'Attempted Administrator Privilege Gain', 'severity': 1, 'metadata': {'confidence': ['Low'], 'created_at': ['2011_02_18'], 'signature_severity': ['Major'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2200004, 'rev': 2, 'signature': 'SURICATA IPv4 invalid option', 'category': 'Generic Protocol Command Decode', 'severity': 3}</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2200008, 'rev': 2, 'signature': 'SURICATA IPv4 option end of list required', 'category': 'Generic Protocol Command Decode', 'severity': 3}</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2101948, 'rev': 8, 'signature': 'GPL DNS zone transfer UDP', 'category': 'Attempted Information Leak', 'severity': 2, 'metadata': {'created_at': ['2010_09_23'], 'cve': ['CVE_1999_0532'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2101411, 'rev': 13, 'signature': 'GPL SNMP public access udp', 'category': 'Attempted Information Leak', 'severity': 2, 'metadata': {'created_at': ['2010_09_23'], 'cve': ['CVE_1999_0517'], 'signature_severity': ['Informational'], 'updated_at': ['2019_10_08']}}</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2101384, 'rev': 9, 'signature': 'GPL MISC UPnP malformed advertisement', 'category': 'Misc Attack', 'severity': 2, 'metadata': {'created_at': ['2010_09_23'], 'cve': ['CVE_2001_0876'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'action': 'allowed', 'gid': 1, 'signature_id': 2002910, 'rev': 6, 'signature': 'ET SCAN Potential VNC Scan 5800-5820', 'category': 'Attempted Information Leak', 'severity': 2, 'metadata': {'confidence': ['Medium'], 'created_at': ['2010_07_30'], 'signature_severity': ['Informational'], 'updated_at': ['2019_07_26']}}</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv')\n",
        "df['alert'].info()\n",
        "#df.head(3)\n",
        "df['alert'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFbcrLXbhOSk",
        "outputId": "dfbec91d-ea2f-43d3-d52e-7f18c5f209ce",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 286150 entries, 0 to 286149\n",
            "Data columns (total 13 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   flow        284361 non-null  object \n",
            " 1   dest_ip     286148 non-null  object \n",
            " 2   src_port    285848 non-null  float64\n",
            " 3   dest_port   285848 non-null  float64\n",
            " 4   proto       286148 non-null  object \n",
            " 5   src_ip      286148 non-null  object \n",
            " 6   event_type  286150 non-null  object \n",
            " 7   tcp         270253 non-null  object \n",
            " 8   flow_id     286048 non-null  float64\n",
            " 9   Date        286150 non-null  int64  \n",
            " 10  hour        137399 non-null  float64\n",
            " 11  minute      137399 non-null  float64\n",
            " 12  second      137399 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(6)\n",
            "memory usage: 28.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/eve_del.csv')\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'tcp' , 'flow'"
      ],
      "metadata": {
        "id": "zzgqZHxUUJOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "u6fZwCS0q5vM",
        "outputId": "e4a8a372-a6ad-41df-df97-c29e1c723675",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "flow\n",
              "{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 186, 'bytes_toclient': 0, 'start': '2016-03-14T12:58:39.946046+0200', 'src_ip': '175.45.176.2', 'dest_ip': '10.40.85.32', 'src_port': 18787, 'dest_port': 32472}                     2\n",
              "{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 62, 'bytes_toclient': 0, 'start': '2016-03-14T12:53:22.979217+0200', 'src_ip': '175.45.176.1', 'dest_ip': '10.40.85.32', 'src_port': 1024, 'dest_port': 4096}                        2\n",
              "{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 62, 'bytes_toclient': 0, 'start': '2016-03-11T06:17:57.852848+0200', 'src_ip': '175.45.176.1', 'dest_ip': '10.40.85.32', 'src_port': 1024, 'dest_port': 4096}                        2\n",
              "{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 121, 'bytes_toclient': 0, 'start': '2016-03-12T08:19:54.090135+0200', 'src_ip': '175.45.176.3', 'dest_ip': '10.40.85.32', 'src_port': 29177, 'dest_port': 29129}                     2\n",
              "{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 118, 'bytes_toclient': 0, 'start': '2016-03-12T05:48:55.075828+0200', 'src_ip': '175.45.176.1', 'dest_ip': '10.40.85.32', 'src_port': 29605, 'dest_port': 58859}                     2\n",
              "                                                                                                                                                                                                                                               ..\n",
              "{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:55:56.377999+0200', 'end': '2016-03-12T05:56:11.821139+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}    1\n",
              "{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:58:34.413321+0200', 'end': '2016-03-12T05:58:49.971013+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}    1\n",
              "{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:32:45.219512+0200', 'end': '2016-03-12T05:33:00.738873+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}    1\n",
              "{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:46:08.426198+0200', 'end': '2016-03-12T05:46:23.959608+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}    1\n",
              "{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:45:02.148386+0200', 'end': '2016-03-12T05:45:17.644881+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}    1\n",
              "Name: count, Length: 284161, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flow</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 186, 'bytes_toclient': 0, 'start': '2016-03-14T12:58:39.946046+0200', 'src_ip': '175.45.176.2', 'dest_ip': '10.40.85.32', 'src_port': 18787, 'dest_port': 32472}</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 62, 'bytes_toclient': 0, 'start': '2016-03-14T12:53:22.979217+0200', 'src_ip': '175.45.176.1', 'dest_ip': '10.40.85.32', 'src_port': 1024, 'dest_port': 4096}</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 62, 'bytes_toclient': 0, 'start': '2016-03-11T06:17:57.852848+0200', 'src_ip': '175.45.176.1', 'dest_ip': '10.40.85.32', 'src_port': 1024, 'dest_port': 4096}</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 121, 'bytes_toclient': 0, 'start': '2016-03-12T08:19:54.090135+0200', 'src_ip': '175.45.176.3', 'dest_ip': '10.40.85.32', 'src_port': 29177, 'dest_port': 29129}</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 1, 'pkts_toclient': 0, 'bytes_toserver': 118, 'bytes_toclient': 0, 'start': '2016-03-12T05:48:55.075828+0200', 'src_ip': '175.45.176.1', 'dest_ip': '10.40.85.32', 'src_port': 29605, 'dest_port': 58859}</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:55:56.377999+0200', 'end': '2016-03-12T05:56:11.821139+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:58:34.413321+0200', 'end': '2016-03-12T05:58:49.971013+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:32:45.219512+0200', 'end': '2016-03-12T05:33:00.738873+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:46:08.426198+0200', 'end': '2016-03-12T05:46:23.959608+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>{'pkts_toserver': 4, 'pkts_toclient': 0, 'bytes_toserver': 248, 'bytes_toclient': 0, 'start': '2016-03-12T05:45:02.148386+0200', 'end': '2016-03-12T05:45:17.644881+0200', 'age': 15, 'state': 'new', 'reason': 'timeout', 'alerted': False}</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284161 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df['flow'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs525Z4rh4e3",
        "outputId": "a1508e40-57f5-49b6-f9f7-46ac48f2af14",
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Date\n",
              " 3    148751\n",
              " 1     69401\n",
              " 2     54913\n",
              " 0     13085\n",
              " Name: count, dtype: int64,\n",
              " array([0, 1, 2, 3]))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " df['Date'].value_counts(),df['Date'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date']"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "pxMVNo11ZWWU",
        "outputId": "944074bf-1cc6-4fb5-e3b4-398f2a4d7422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "286145    3\n",
              "286146    3\n",
              "286147    3\n",
              "286148    3\n",
              "286149    3\n",
              "Name: Date, Length: 286150, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286145</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286146</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286147</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286148</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286149</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>286150 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZCP9zxIaglIA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK3sW0cEkbB_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class Preprocessing:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def clean_and_save(self, file_path: str, output_path: str, threshold=80):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        total_rows = len(df)\n",
        "        missing_ratios = (df.isnull().sum() / total_rows) * 100\n",
        "\n",
        "        columns_to_drop = [col for col, ratio in missing_ratios.items() if ratio > threshold]\n",
        "\n",
        "        print(f\"Columns to drop: {columns_to_drop}\")\n",
        "\n",
        "        df = df.drop(columns=columns_to_drop, axis=1)\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return f\"Saved cleaned data to {output_path}\"\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def data_encoding(self, file_path, column_number : int):\n",
        "    encoder = LabelEncoder()\n",
        "    tqdm.pandas()\n",
        "    try:\n",
        "\n",
        "      df = pd.read_csv(file_path)\n",
        "      df.iloc[:, column_number] = df.iloc[:, column_number].astype(str).fillna(-1)\n",
        "\n",
        "      encoder.fit(df.iloc[:, column_number])\n",
        "      df.iloc[:, column_number] = df.iloc[:, column_number].progress_apply(\n",
        "          lambda x:encoder.transform([x])[0] if pd.notna(x) else -1 )\n",
        "\n",
        "      df.to_csv(file_path.replace(\".csv\", \"_encoded.csv\"), index=False)\n",
        "      return f\"done file...\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def expand_dict_columns(self, file_path, column_names: list, output_file_path: str = None):\n",
        "        try:\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            all_keys = set()\n",
        "\n",
        "            # المرحلة 1: اجمع جميع المفاتيح لكل الأعمدة المطلوبة\n",
        "            for column_name in column_names:\n",
        "                if column_name not in df.columns:\n",
        "                    continue  # تجاهل أي عمود غير موجود\n",
        "\n",
        "                # استخدام apply بدلاً من iterrows لتسريع العملية\n",
        "                def extract_keys(value):\n",
        "                    if pd.notna(value):\n",
        "                        try:\n",
        "                            return ast.literal_eval(value).keys()\n",
        "                        except (SyntaxError, ValueError):\n",
        "                            return []\n",
        "                    return []\n",
        "\n",
        "                # اجمع كل المفاتيح\n",
        "                all_keys.update(df[column_name].apply(extract_keys).explode().dropna().unique())\n",
        "\n",
        "            # أضف الأعمدة الجديدة (المفاتيح)\n",
        "            for key in all_keys:\n",
        "                if key not in df.columns:\n",
        "                    df[key] = np.nan\n",
        "\n",
        "            # المرحلة 2: عبئ القيم من كل الأعمدة المطلوبة باستخدام apply\n",
        "            def expand_dict_column(value, column_name):\n",
        "                if pd.notna(value):\n",
        "                    try:\n",
        "                        dictionary = ast.literal_eval(value)\n",
        "                        return dictionary.get(column_name, np.nan)\n",
        "                    except (SyntaxError, ValueError):\n",
        "                        return np.nan\n",
        "                return np.nan\n",
        "\n",
        "            # استخدم apply لتوسيع القيم في الأعمدة الجديدة\n",
        "            for column_name in column_names:\n",
        "                if column_name not in df.columns:\n",
        "                    continue\n",
        "                df[column_name].apply(lambda x: expand_dict_column(x, column_name))\n",
        "\n",
        "            # حذف الأعمدة الأصلية بعد التوسيع (اختياري)\n",
        "            df = df.drop(columns=column_names, axis=1)\n",
        "\n",
        "            # حفظ الملف الجديد\n",
        "            output_file_path = output_file_path or file_path.replace(\".csv\", \"_expanded.csv\")\n",
        "            df.to_csv(output_file_path, index=False)\n",
        "\n",
        "            return f\"✅ تم توسيع الأعمدة وحفظ الملف بنجاح في: {output_file_path}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ حدث خطأ: {e}\"\n",
        "\n",
        "\n",
        "a = Preprocessing()\n",
        "#a.data_encoding('/content/drive/MyDrive/hybrid_IDS/dataset/eve.csv',\n",
        "#                column_number=19)\n",
        "\n",
        "#a.clean_and_save(file_path='/content/eve_encoded.csv',\n",
        "#                 output_path='/content/eve_del.csv', threshold=80)\n",
        "a.expand_dict_columns( file_path='/content/eve_del.csv',\n",
        "                     column_names=['tcp' , 'flow'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_dict_column(self, file_path, column_name: str):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # 1. Extract all unique keys from the dictionaries in the column\n",
        "        all_keys = set()\n",
        "        for index in df.index:\n",
        "            if pd.notna(df.loc[index, column_name]):\n",
        "                try:  # Handle potential errors in ast.literal_eval\n",
        "                    dictionary = ast.literal_eval(df.loc[index, column_name])\n",
        "                    all_keys.update(dictionary.keys())\n",
        "                except (SyntaxError, ValueError):\n",
        "                    pass  # Skip rows with invalid dictionary strings\n",
        "\n",
        "        # 2. Pre-fill new columns with NaN to accommodate missing keys\n",
        "        for key in all_keys:\n",
        "            df[key] = np.nan\n",
        "\n",
        "        # 3. Populate the new columns with values from the dictionaries\n",
        "        for index in df.index:\n",
        "            if pd.notna(df.loc[index, column_name]):\n",
        "                try:\n",
        "                    dictionary = ast.literal_eval(df.loc[index, column_name])\n",
        "                    for key, value in dictionary.items():\n",
        "                        df.loc[index, key] = value\n",
        "                except (SyntaxError, ValueError):\n",
        "                    pass  # Skip rows with invalid dictionary strings\n",
        "\n",
        "        # 4. Drop the original dictionary column\n",
        "        df = df.drop(columns=[column_name])\n",
        "\n",
        "        df.to_csv(file_path, index=False)\n",
        "        return \"done file...\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\""
      ],
      "metadata": {
        "id": "lgG5NxZT5gHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['flow']"
      ],
      "metadata": {
        "id": "s6CuzkZ-s5Dh",
        "outputId": "571cc02e-2a86-47fa-a03d-c8300bb525e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                       NaN\n",
              "1         {'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...\n",
              "2         {'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...\n",
              "3                                                       NaN\n",
              "4         {'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...\n",
              "                                ...                        \n",
              "286145    {'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...\n",
              "286146    {'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...\n",
              "286147    {'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...\n",
              "286148    {'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...\n",
              "286149                                                  NaN\n",
              "Name: flow, Length: 286150, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286145</th>\n",
              "      <td>{'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286146</th>\n",
              "      <td>{'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286147</th>\n",
              "      <td>{'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286148</th>\n",
              "      <td>{'pkts_toserver': 1, 'pkts_toclient': 0, 'byte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286149</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>286150 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "#df = df.drop(df.iloc[:,11], axis=1)\n",
        "df.info()\n",
        "df.loc[5, 5]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QF6WL0ZbkkZ3",
        "outputId": "ab91ba09-c3f2-4d69-aa22-f4b130a59ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-53841a2ac594>:2: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA4up3e0gunz"
      },
      "outputs": [],
      "source": [
        "class NetworkPreprocessing:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "  def extract_tcp_option(self, option, key):\n",
        "    for opt in option:\n",
        "      if opt[0] == key:\n",
        "        return opt[1]\n",
        "    return None\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "  def convert_pcap_csv(self, pcap_file, csv_file):\n",
        "    try:\n",
        "      print(\"Countig packages...\")\n",
        "      with PcapReader(pcap_file) as count_reader:\n",
        "        total_packets = sum(1 for _ in count_reader)\n",
        "        print(f\"Total number of packages: {total_packets}\")\n",
        "\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with PcapReader(pcap_file) as packets:\n",
        "        with open(csv_file, mode='w', newline=\"\") as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([\n",
        "              \"Packet Number\", \"Ethernet DST\", \"Ethernet SRC\", \"Ethernet Type\",\n",
        "              \"IP Version\", \"IP IHL\", \"IP TOS\", \"IP Length\", \"IP ID\", \"IP Flags\",\n",
        "              \"IP Fragmentation\", \"IP TTL\", \"IP Proto\", \"IP Checksum\",\n",
        "              \"IP Src\", \"IP Dst\", \"TCP Src Port\", \"TCP Dst Port\", \"TCP Seq\",\n",
        "              \"TCP Ack\", \"TCP Data Offset\", \"TCP Reserved\", \"TCP Flags\",\n",
        "              \"TCP Window\", \"TCP Checksum\", \"TCP Urgent Pointer\", \"TCP Options MSS\",\n",
        "              \"TCP Options WScale\", \"TCP Options NOP\",\"Hexdump\"\n",
        "          ])\n",
        "\n",
        "          for i, packet in enumerate(tqdm(packets,total=total_packets, desc=\"Packet processing\")):\n",
        "            if packet.haslayer('Ethernet'):\n",
        "              eth_dst = packet['Ethernet'].dst\n",
        "              eth_src = packet['Ethernet'].src\n",
        "              eth_type = packet['Ethernet'].type\n",
        "            else:\n",
        "              eth_dst = eth_src = eth_type = None\n",
        "\n",
        "            if packet.haslayer('IP'):\n",
        "              ip_version = packet['IP'].version\n",
        "              ip_ihl = packet['IP'].ihl\n",
        "              ip_tos = packet['IP'].tos\n",
        "              ip_len = packet['IP'].len\n",
        "              ip_id = packet['IP'].id\n",
        "              ip_flags = packet['IP'].flags\n",
        "              ip_frag = packet['IP'].frag\n",
        "              ip_ttl = packet['IP'].ttl\n",
        "              ip_proto = packet['IP'].proto\n",
        "              ip_chksum = packet['IP'].chksum\n",
        "              ip_src = packet['IP'].src\n",
        "              ip_dst = packet['IP'].dst\n",
        "            else:\n",
        "              ip_version = ip_ihl = ip_tos = ip_len = ip_id = ip_flags = ip_frag = ip_ttl = ip_proto = ip_chksum = ip_src = ip_dst = None\n",
        "\n",
        "            if packet.haslayer('TCP'):\n",
        "              tcp_sport = packet['TCP'].sport\n",
        "              tcp_dport = packet['TCP'].dport\n",
        "              tcp_seq = packet['TCP'].seq\n",
        "              tcp_ack = packet['TCP'].ack\n",
        "              tcp_dataofs = packet['TCP'].dataofs\n",
        "              tcp_reserved = packet['TCP'].reserved\n",
        "              tcp_flags = packet['TCP'].flags\n",
        "              tcp_window = packet['TCP'].window\n",
        "              tcp_chksum = packet['TCP'].chksum\n",
        "              tcp_urgptr = packet['TCP'].urgptr\n",
        "              tcp_options = packet['TCP'].options\n",
        "\n",
        "              tcp_mss = self.extract_tcp_option(tcp_options, 'MSS')\n",
        "              tcp_wscale = self.extract_tcp_option(tcp_options, 'WScale')\n",
        "              tcp_nop_count = self.extract_tcp_option(tcp_options, 'NOP')\n",
        "\n",
        "            else:\n",
        "              tcp_sport = tcp_dport = tcp_seq = tcp_ack = tcp_dataofs = tcp_reserved = tcp_flags = tcp_window = tcp_chksum = tcp_urgptr = tcp_mss = tcp_wscale = tcp_nop_count = None\n",
        "\n",
        "            raw_data = packet.original.hex()\n",
        "            writer.writerow([\n",
        "                i + 1, eth_dst, eth_src, eth_type,\n",
        "                  ip_version, ip_ihl, ip_tos, ip_len, ip_id, ip_flags,\n",
        "                  ip_frag, ip_ttl, ip_proto, ip_chksum,\n",
        "                  ip_src, ip_dst, tcp_sport, tcp_dport, tcp_seq,\n",
        "                  tcp_ack, tcp_dataofs, tcp_reserved, tcp_flags,\n",
        "                  tcp_window, tcp_chksum, tcp_urgptr, tcp_mss, tcp_wscale, tcp_nop_count,\n",
        "                  raw_data\n",
        "            ])\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "a = NetworkPreprocessing()\n",
        "#a.convert_pcap_csv(pcap_file='/content/NGIDS/NGIDS-DS-v1/NGIDS.pcap',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/network.csv')\n",
        "#a.delete_data(file_path='/content/drive/MyDrive/hybrid_IDS/network.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0gugEuMgvIQ"
      },
      "outputs": [],
      "source": [
        "class PcapFileProcessing:\n",
        "  def __init__(self) -> None:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "\n",
        "  def date_time_columns(self, file_path, csv_file):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, dtype=str)\n",
        "        df.columns = df.columns.str.strip()\n",
        "        if 'timestamp' not in df.columns:\n",
        "            return \"Error: The 'timestamp' column is missing from the file.\"\n",
        "\n",
        "        df['timestamp'] = df['timestamp'].astype(str).str.strip()\n",
        "\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', dayfirst=True)\n",
        "\n",
        "        if df['timestamp'].isnull().all():\n",
        "            return \"All values in 'timestamp' are invalid and could not be converted.\"\n",
        "\n",
        "        # Extract date and time\n",
        "        df['date'] = df['timestamp'].dt.strftime('%d/%m/%Y')\n",
        "        df['time'] = df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "        # Save the result\n",
        "        df.to_csv(csv_file, index=False)\n",
        "\n",
        "        return \"Successfully converted 'timestamp' to 'date' and 'time'.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during conversion: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def convert_log_csv(self, log_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with open(log_file, \"r\") as logfile:\n",
        "        log_data = logfile.read()\n",
        "      pattern = re.compile(\n",
        "          r'(?P<timestamp>\\d{2}/\\d{2}/\\d{4}-\\d{2}:\\d{2}:\\d{2}\\.\\d+)\\s+\\[\\*\\*\\]\\s+\\[(?P<sid>[^]]+)\\]\\s+(?P<signature>.*?)\\s+\\[\\*\\*\\]\\s+\\[Classification:\\s+(?P<classification>.*?)\\]\\s+\\[Priority:\\s+(?P<priority>\\d+)\\]\\s+\\{(?P<protocol>\\w+)\\}\\s+(?P<src_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<src_port>\\d+)\\s+->\\s+(?P<dst_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<dst_port>\\d+)'\n",
        "          )\n",
        "      with open(csv_file, \"w\", newline=\"\") as csvfile:\n",
        "        fieldnames = ['timestamp', 'sid', 'signature', 'classification',\n",
        "                      'priority', 'protocol','src_ip', 'src_port', 'dst_ip', 'dst_port']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for match in pattern.finditer(log_data):\n",
        "          writer.writerow(match.groupdict())\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def convert_json_csv(self, json_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting JSON to CSV...\")\n",
        "      with open(json_file, 'r') as f:\n",
        "        data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "      fieldnames = set()\n",
        "      for row in data:\n",
        "          fieldnames.update(row.keys())\n",
        "\n",
        "      fieldnames = list(fieldnames)\n",
        "\n",
        "      with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(fieldnames)\n",
        "\n",
        "        for row in data:\n",
        "          writer.writerow(row.get(field, '') for field in fieldnames)\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "a = PcapFileProcessing()\n",
        "#a.convert_log_csv( log_file=\"/content/drive/MyDrive/hybrid_IDS/fast.log\",\n",
        "#                  csv_file=\"/content/drive/MyDrive/hybrid_IDS/alerts.csv\")\n",
        "\n",
        "#a.convert_json_csv(json_file='/content/drive/MyDrive/hybrid_IDS/eve.json',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "\n",
        "#a.delete_data( file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "a.date_time_columns(file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv',\n",
        "                    csv_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/hananbahtiti/Hybrid-Intrusion-detection-Systems/blob/main/NetworkPreprocessing.ipynb",
      "authorship_tag": "ABX9TyM/eWTZ4WheYnthpVoJl1No",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}