{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hananbahtiti/Hybrid-Intrusion-detection-Systems/blob/main/NetworkPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/eve_encoded.csv /content/drive/MyDrive/hybrid_IDS/dataset/"
      ],
      "metadata": {
        "id": "LBZjWIJjDPvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "NSXj-h-NqUET",
        "outputId": "bd43e734-1884-45f2-8558-34c4b0fab7d8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 286150 entries, 0 to 286149\n",
            "Data columns (total 17 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   proto           286150 non-null  int64  \n",
            " 1   event_type      286150 non-null  int64  \n",
            " 2   flow_id         286048 non-null  float64\n",
            " 3   Date            286150 non-null  int64  \n",
            " 4   hour            137399 non-null  float64\n",
            " 5   minute          137399 non-null  float64\n",
            " 6   second          137399 non-null  float64\n",
            " 7   pkts_toclient   284361 non-null  float64\n",
            " 8   bytes_toserver  284361 non-null  float64\n",
            " 9   bytes_toclient  284361 non-null  float64\n",
            " 10  tcp_flags       270253 non-null  float64\n",
            " 11  alerted         286150 non-null  int64  \n",
            " 12  age             279361 non-null  float64\n",
            " 13  reason          286150 non-null  int64  \n",
            " 14  pkts_toserver   284361 non-null  float64\n",
            " 15  tcp_flags_ts    270253 non-null  float64\n",
            " 16  state           286150 non-null  int64  \n",
            "dtypes: float64(11), int64(6)\n",
            "memory usage: 37.1 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   proto  event_type       flow_id  Date  hour  minute  second  pkts_toclient  \\\n",
              "0      4           0           NaN     0  17.0    49.0    10.0            NaN   \n",
              "1      4           0  2.558362e+14     0  17.0    49.0    44.0            0.0   \n",
              "2      4           0  2.558362e+14     0  17.0    49.0    44.0            0.0   \n",
              "3      5           8  5.620575e+13     0  17.0    49.0    36.0            NaN   \n",
              "4      4           2  8.582737e+14     0  17.0    48.0    59.0            0.0   \n",
              "\n",
              "   bytes_toserver  bytes_toclient  tcp_flags  alerted  age  reason  \\\n",
              "0             NaN             NaN        NaN        0  NaN       0   \n",
              "1            62.0             0.0        NaN        0  NaN       0   \n",
              "2            62.0             0.0        NaN        0  NaN       0   \n",
              "3             NaN             NaN        NaN        0  NaN       0   \n",
              "4            60.0             0.0        0.0        1  0.0       2   \n",
              "\n",
              "   pkts_toserver  tcp_flags_ts  state  \n",
              "0            NaN           NaN      0  \n",
              "1            1.0           NaN      0  \n",
              "2            1.0           NaN      0  \n",
              "3            NaN           NaN      0  \n",
              "4            1.0           0.0      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82218ee2-6873-4ee3-aa7b-5399124d18d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proto</th>\n",
              "      <th>event_type</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "      <th>pkts_toclient</th>\n",
              "      <th>bytes_toserver</th>\n",
              "      <th>bytes_toclient</th>\n",
              "      <th>tcp_flags</th>\n",
              "      <th>alerted</th>\n",
              "      <th>age</th>\n",
              "      <th>reason</th>\n",
              "      <th>pkts_toserver</th>\n",
              "      <th>tcp_flags_ts</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2.558362e+14</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2.558362e+14</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>5.620575e+13</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8.582737e+14</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82218ee2-6873-4ee3-aa7b-5399124d18d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82218ee2-6873-4ee3-aa7b-5399124d18d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82218ee2-6873-4ee3-aa7b-5399124d18d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f9da2e4-491e-4a20-a087-ee3174403111\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f9da2e4-491e-4a20-a087-ee3174403111')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f9da2e4-491e-4a20-a087-ee3174403111 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#df['alert']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"proto\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flow_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 347476561303567.6,\n        \"min\": 56205748182235.0,\n        \"max\": 858273710959543.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          255836220392957.0,\n          56205748182235.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 17.0,\n        \"max\": 17.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"minute\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4472135954999579,\n        \"min\": 48.0,\n        \"max\": 49.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          48.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.022208521710095,\n        \"min\": 10.0,\n        \"max\": 59.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          44.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pkts_toclient\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bytes_toserver\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1547005383792517,\n        \"min\": 60.0,\n        \"max\": 62.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          60.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bytes_toclient\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tcp_flags\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alerted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reason\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pkts_toserver\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tcp_flags_ts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv')\n",
        "df.info()\n",
        "df.head()\n",
        "#df['alert'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZCP9zxIaglIA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import ast\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "euRn5oZ_HZv0",
        "outputId": "d8ee529c-f921-4799-8956-23313f65760b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from tqdm import tqdm\n",
        "    TQDM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TQDM_AVAILABLE = False"
      ],
      "metadata": {
        "id": "xqC3EGR9hY_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "aK3sW0cEkbB_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class Preprocessing:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def clean_and_save(self, file_path: str, output_path: str, threshold=80):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        total_rows = len(df)\n",
        "        missing_ratios = (df.isnull().sum() / total_rows) * 100\n",
        "\n",
        "        columns_to_drop = [col for col, ratio in missing_ratios.items() if ratio > threshold]\n",
        "\n",
        "        print(f\"Columns to drop: {columns_to_drop}\")\n",
        "\n",
        "        df = df.drop(columns=columns_to_drop, axis=1)\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return f\"Saved cleaned data to {output_path}\"\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def columns_drop(self, file_path: str, columns_names: list, output_path: str):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df.drop(columns=columns_names, axis=1)  # Drop columns once\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return f\"Saved cleaned data to {output_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def data_encoding(self, file_path, columns_names: list):\n",
        "    encoder = LabelEncoder()\n",
        "    tqdm.pandas()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)  # قراءة الملف مرة واحدة فقط\n",
        "\n",
        "        for col in columns_names:\n",
        "            df.loc[:, col] = df.loc[:, col].fillna(\"-1\").astype(str)\n",
        "\n",
        "            encoder.fit(df.loc[:, col])\n",
        "\n",
        "            # تحديث شريط التقدم بحيث يظهر اسم العمود\n",
        "            with tqdm(total=len(df), desc=f\"Encoding '{col}'\", unit=\"rows\") as pbar:\n",
        "                def encoding_function(x):\n",
        "                    result = encoder.transform([x])[0] if pd.notna(x) else -1\n",
        "                    pbar.update(1)\n",
        "                    return result\n",
        "\n",
        "                df.loc[:, col] = df.loc[:, col].apply(encoding_function)\n",
        "\n",
        "        output_path = file_path.replace(\".csv\", \"_encoded.csv\")\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return f\"Done. Encoded file saved to: {output_path}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "  def drop_constant_columns(self, file_path, output_path=None):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        constant_columns = [col for col in df.columns if df[col].nunique(dropna=True) == 1]\n",
        "        print(f\"Columns with constant value: {constant_columns}\")\n",
        "\n",
        "        df = df.drop(columns=constant_columns)\n",
        "        if output_path is None:\n",
        "          output_path = file_path.replace('.csv', '_no_constant.csv')\n",
        "        df.to_csv(output_path, index=False)\n",
        "\n",
        "        return f\"Saved cleaned file to {output_path}\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "  def show_column_types(self, file_path):\n",
        "    try:\n",
        "      columns_names = []\n",
        "      df = pd.read_csv(file_path)\n",
        "      [columns_names.append(col)  for col in df.columns if df[col].dtype == 'object']\n",
        "\n",
        "      return columns_names\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def expand_dict_columns( file_path, column_names: list, output_file_path: str = None):\n",
        "      try:\n",
        "          df = pd.read_csv(file_path)\n",
        "\n",
        "          all_keys = set()\n",
        "\n",
        "          # Step 1: Extract all keys\n",
        "          def extract_keys(value):\n",
        "              if pd.notna(value):\n",
        "                  try:\n",
        "                      return ast.literal_eval(value).keys()\n",
        "                  except (SyntaxError, ValueError):\n",
        "                      return []\n",
        "              return []\n",
        "\n",
        "          print(\"🔍 Extracting all keys...\")\n",
        "\n",
        "          for column_name in column_names:\n",
        "              if column_name in df.columns:\n",
        "                  all_keys.update(df[column_name].apply(extract_keys).explode().dropna().unique())\n",
        "\n",
        "          print(f\"✅ Extracted {len(all_keys)} unique keys.\")\n",
        "\n",
        "          # Step 2: Create new columns and fill values\n",
        "          if TQDM_AVAILABLE:\n",
        "              progress_bar = tqdm(all_keys, desc=\"🚀 Expanding values\", ncols=80)\n",
        "          else:\n",
        "              progress_bar = all_keys\n",
        "\n",
        "          for idx, key in enumerate(progress_bar):\n",
        "              df[key] = np.nan\n",
        "              for column_name in column_names:\n",
        "                  if column_name in df.columns:\n",
        "                      df[key] = df[key].combine_first(\n",
        "                          df[column_name].apply(lambda x: Preprocessing.expand_dict_column(x, key))\n",
        "                      )\n",
        "\n",
        "              # Print manual progress if tqdm is not available\n",
        "              if not TQDM_AVAILABLE and idx % max(1, len(all_keys)//10) == 0:\n",
        "                  print(f\"📈 Progress: {idx}/{len(all_keys)} keys expanded...\")\n",
        "\n",
        "          # Step 3: Drop original dictionary columns\n",
        "          df = df.drop(columns=column_names, axis=1)\n",
        "\n",
        "          # Step 4: Save the new file\n",
        "          output_file_path = output_file_path or file_path.replace(\".csv\", \"_expanded.csv\")\n",
        "          df.to_csv(output_file_path, index=False)\n",
        "\n",
        "          return f\"✅ Columns expanded and file saved successfully at: {output_file_path}\"\n",
        "\n",
        "      except Exception as e:\n",
        "          return f\"❌ An error occurred: {e}\"\n",
        "\n",
        "  @staticmethod\n",
        "  def expand_dict_column( value, column_name):\n",
        "      if pd.notna(value):\n",
        "          try:\n",
        "              dictionary = ast.literal_eval(value)\n",
        "              return dictionary.get(column_name, np.nan)\n",
        "          except (SyntaxError, ValueError):\n",
        "              return np.nan\n",
        "      return np.nan\n",
        "\n",
        "\n",
        "  def get_corr(self, file, column: str, threshold=0.05):\n",
        "    try:\n",
        "      df = pd.read_csv(file)\n",
        "\n",
        "      corr = df.corr(method='pearson')[column]\n",
        "      corr_series = pd.Series(dict(corr.items()))\n",
        "      values = [(value, index ) for value, index in corr_series.sort_values().items() if abs(index) >= threshold or pd.isna(index) ]\n",
        "      return values\n",
        "    except Exception as e:\n",
        "          return f\"❌ An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "  def smart_impute_and_save(self, input_file, output_file):\n",
        "    \"\"\"\n",
        "    This method automatically fills missing values based on missing ratios,\n",
        "    then saves the cleaned data to a new CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        start_time = time.time()  # Start timing ⏱️\n",
        "        # Load the data\n",
        "        df = pd.read_csv(input_file)\n",
        "\n",
        "        # Get columns to impute based on correlation with 'event_type'\n",
        "        cols_to_impute = self.get_corr(input_file, column='event_type')  # Use self.get_corr if inside a class\n",
        "        cols_to_impute = [value for value, index in cols_to_impute]  # Extract column names only\n",
        "        df = df[cols_to_impute]\n",
        "\n",
        "        # Remove duplicate columns (optional)\n",
        "        df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "        # Build the feature set\n",
        "        features = df.copy()\n",
        "\n",
        "        # Calculate missing value ratios\n",
        "        missing_ratio = features.isna().mean()\n",
        "        print(\"📊 Missing value ratio per column:\\n\", missing_ratio)\n",
        "\n",
        "        # Smart imputation\n",
        "        for col in tqdm(cols_to_impute, desc=\"Imputing columns\", unit=\"column\"):\n",
        "            if col not in df.columns:\n",
        "                continue  # Skip if the column was dropped or doesn't exist\n",
        "\n",
        "            ratio = missing_ratio[col]\n",
        "            print(f\"\\n=== Processing column: {col} (Missing {ratio:.2%}) ===\")\n",
        "\n",
        "            if ratio > 0.90:\n",
        "                print(f\"⚠️  Column {col} has too many missing values (>90%). Dropping it...\")\n",
        "                df.drop(columns=[col], inplace=True)\n",
        "\n",
        "            elif ratio < 0.3:\n",
        "                print(f\"🛠️  Using Iterative Imputer for {col}...\")\n",
        "                imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "                temp_data = features[[col]]\n",
        "                # Using IterativeImputer\n",
        "                imputed_data = imputer.fit_transform(temp_data)\n",
        "                df[col] = imputed_data[:, 0]\n",
        "\n",
        "            else:\n",
        "                print(f\"🔍 Using KNN Imputer for {col}...\")\n",
        "                imputer = KNNImputer(n_neighbors=5)\n",
        "                temp_data = features[[col]]\n",
        "                # Using KNNImputer\n",
        "                imputed_data = imputer.fit_transform(temp_data)\n",
        "                df[col] = imputed_data[:, 0]\n",
        "\n",
        "        # Save the cleaned data\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"\\n✅ Successfully completed missing value filling and saved to {output_file}.\")\n",
        "\n",
        "        end_time = time.time()  # End timing ⏱️\n",
        "        elapsed_time = end_time - start_time\n",
        "        print(f\"⏱️ Total execution time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "a = Preprocessing()\n",
        "#a.data_encoding('/content/drive/MyDrive/hybrid_IDS/dataset/eve.csv',\n",
        "#                column_number=19)\n",
        "\n",
        "#a.clean_and_save(file_path='/content/eve_del_expanded.csv',\n",
        " #                output_path='/content/eve_tag.csv', threshold=80)\n",
        "#a.expand_dict_columns( file_path='/content/eve_del.csv',\n",
        " #                    column_names=['tcp' , 'flow'])\n",
        "#a.drop_constant_columns(file_path='/content/eve_tag.csv')\n",
        "\n",
        "#c= a.show_column_types( file_path='/content/eve.csv')\n",
        "#a.data_encoding(file_path='/content/eve.csv',\n",
        " #              columns_names=c)\n",
        "v=a.get_corr(file= '/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv',\n",
        "           column='event_type', threshold=0.05)\n",
        "#a.smart_impute_and_save( input_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv',\n",
        " #                       output_file='/content/eve_output.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/final_nan9.csv')\n",
        "df.info()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "JVHkSh7wBYqM",
        "outputId": "89768076-5d25-46ed-b087-c33e8204f4f3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 286150 entries, 0 to 286149\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   bytes_toserver  286150 non-null  float64\n",
            " 1   pkts_toserver   286150 non-null  float64\n",
            " 2   alerted         286150 non-null  int64  \n",
            " 3   state           286150 non-null  int64  \n",
            " 4   reason          286150 non-null  int64  \n",
            " 5   event_type      286150 non-null  int64  \n",
            " 6   tcp_flags       286150 non-null  float64\n",
            " 7   age             286150 non-null  float64\n",
            " 8   tcp_flags_ts    286150 non-null  float64\n",
            "dtypes: float64(5), int64(4)\n",
            "memory usage: 19.6 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   bytes_toserver  pkts_toserver  alerted  state  reason  event_type  \\\n",
              "0           111.6            1.8        0      0       0           0   \n",
              "1            62.0            1.0        0      0       0           0   \n",
              "2            62.0            1.0        0      0       0           0   \n",
              "3           318.6            1.0        0      0       0           8   \n",
              "4            60.0            1.0        1      1       2           2   \n",
              "\n",
              "   tcp_flags  age  tcp_flags_ts  \n",
              "0        6.0  0.0           6.0  \n",
              "1        6.0  0.0           6.0  \n",
              "2        6.0  0.0           6.0  \n",
              "3        6.0  0.0           6.0  \n",
              "4        0.0  0.0           0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97de7f2b-63bb-4beb-9e03-44b26fd4ac96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bytes_toserver</th>\n",
              "      <th>pkts_toserver</th>\n",
              "      <th>alerted</th>\n",
              "      <th>state</th>\n",
              "      <th>reason</th>\n",
              "      <th>event_type</th>\n",
              "      <th>tcp_flags</th>\n",
              "      <th>age</th>\n",
              "      <th>tcp_flags_ts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111.6</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>318.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97de7f2b-63bb-4beb-9e03-44b26fd4ac96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97de7f2b-63bb-4beb-9e03-44b26fd4ac96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97de7f2b-63bb-4beb-9e03-44b26fd4ac96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-166dbd5e-5be5-44e2-96c8-b59e1cf9b9e1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-166dbd5e-5be5-44e2-96c8-b59e1cf9b9e1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-166dbd5e-5be5-44e2-96c8-b59e1cf9b9e1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def get_corr(file, column: str, threshold=0.05):\n",
        "    try:\n",
        "      df = pd.read_csv(file)\n",
        "\n",
        "      corr = df.corr(method='pearson')[column]\n",
        "      corr_series = pd.Series(dict(corr.items()))\n",
        "      values = [(value, index ) for value, index in corr_series.sort_values().items() if abs(index) >= threshold or pd.isna(index) ]\n",
        "      return values\n",
        "    except Exception as e:\n",
        "          return f\"❌ An error occurred: {e}\"\n",
        "\n",
        "\n",
        "def smart_impute_and_save(input_file, output_file, knn_threshold=0.3, drop_threshold=0.8):\n",
        "    \"\"\"\n",
        "    Impute missing values using smart techniques without chunking, with progress bar.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the full dataset at once\n",
        "        df = pd.read_csv(input_file)\n",
        "        df = df.apply(pd.to_numeric, errors='coerce')  # Ensure all data is numeric\n",
        "\n",
        "        # Get relevant columns based on correlation\n",
        "        corr = get_corr(input_file, column='event_type')\n",
        "        cols_to_impute = [value for value, index in corr]  # Extract column names\n",
        "        df = df[cols_to_impute]\n",
        "\n",
        "        # Calculate missing value ratios\n",
        "        missing_ratio = df.isna().mean()\n",
        "\n",
        "        # Columns without missing values\n",
        "        notnan_cols = [col for col, ratio in missing_ratio.items() if ratio == 0.0]\n",
        "        # Columns with missing values\n",
        "        cols_to_impute = [col for col, ratio in missing_ratio.items() if ratio > 0.0]\n",
        "\n",
        "        print(\"📊 Missing value ratios:\")\n",
        "        print(missing_ratio[missing_ratio > 0])\n",
        "\n",
        "        features = df.copy()\n",
        "\n",
        "        # Progress bar for imputation\n",
        "        for col in tqdm(cols_to_impute, desc=\"🧠 Imputing columns\", ncols=100):\n",
        "            ratio = missing_ratio[col]\n",
        "\n",
        "            if ratio > drop_threshold:\n",
        "                print(f\"⚠️ Dropping column '{col}' due to high missing ratio ({ratio:.2%})\")\n",
        "                df.drop(columns=[col], inplace=True)\n",
        "                continue\n",
        "\n",
        "            temp_cols = notnan_cols + [col]\n",
        "            temp_data = features[temp_cols].copy()\n",
        "\n",
        "            if ratio > knn_threshold:\n",
        "                imputer = IterativeImputer(max_iter=50, random_state=0)\n",
        "            else:\n",
        "                imputer = KNNImputer(n_neighbors=10)\n",
        "\n",
        "            imputed = imputer.fit_transform(temp_data)\n",
        "            df[col] = imputed[:, -1]\n",
        "\n",
        "        # Save the cleaned file\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"\\n✅ File saved successfully to: {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred: {e}\")\n",
        "\n",
        "\n",
        "# تنفيذ الدالة\n",
        "smart_impute_and_save(\n",
        "    input_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv',\n",
        "    output_file='/content/final.csv'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "9PMcK2NP1wRm",
        "outputId": "103d0d8d-f877-4698-eff4-1987c9727334"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Missing value ratios:\n",
            "bytes_toserver    0.006252\n",
            "pkts_toserver     0.006252\n",
            "tcp_flags         0.055555\n",
            "age               0.023725\n",
            "tcp_flags_ts      0.055555\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Imputing columns:  60%|█████████████████████████▊                 | 3/5 [07:58<05:19, 159.56s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-fbd62ef771d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# تنفيذ الدالة\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m smart_impute_and_save(\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0minput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/final.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-fbd62ef771d5>\u001b[0m in \u001b[0;36msmart_impute_and_save\u001b[0;34m(input_file, output_file, knn_threshold, drop_threshold)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mimputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         )\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;31m# process_chunk modifies X in place. No return value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2253\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   2254\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2478\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0mpresent_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmissing_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0mpresent_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_X\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmissing_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m     \u001b[0mpresent_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m     \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpresent_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;31m# avoid divide by zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_corr(file, column: str, threshold=0.05):\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        corr = df.corr(method='pearson')[column]\n",
        "        corr_series = pd.Series(dict(corr.items()))\n",
        "        values = [(value, index ) for value, index in corr_series.sort_values().items() if abs(index) >= threshold or pd.isna(index) ]\n",
        "        return values\n",
        "    except Exception as e:\n",
        "        return f\"❌ An error occurred: {e}\"\n",
        "\n",
        "def calculate_rmse(original_data, imputed_data):\n",
        "    \"\"\"Calculate RMSE between the original and imputed data\"\"\"\n",
        "    return np.sqrt(mean_squared_error(original_data, imputed_data))\n",
        "\n",
        "def plot_comparison(original_data, imputed_data):\n",
        "    \"\"\"Plot Scatter plot and Histogram for comparison\"\"\"\n",
        "\n",
        "    # Scatter Plot\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(original_data, imputed_data, alpha=0.5)\n",
        "    plt.title('Scatter Plot: Original vs Imputed')\n",
        "    plt.xlabel('Original Data')\n",
        "    plt.ylabel('Imputed Data')\n",
        "\n",
        "    # Histogram\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist([original_data, imputed_data], label=['Original', 'Imputed'], bins=30, alpha=0.7)\n",
        "    plt.title('Histogram: Original vs Imputed')\n",
        "    plt.xlabel('Data Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def grid_search_imputation(imputer, param_grid, data):\n",
        "    \"\"\"Apply GridSearchCV for selecting the best imputation model\"\"\"\n",
        "    grid_search = GridSearchCV(imputer, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "    grid_search.fit(data)\n",
        "    return grid_search.best_estimator_, grid_search.best_params_\n",
        "\n",
        "def smart_impute_and_save(input_file, output_file, knn_threshold=0.3, drop_threshold=0.8):\n",
        "    \"\"\"\n",
        "    Impute missing values using smart techniques, calculate RMSE and plot comparison with GridSearchCV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the full dataset at once\n",
        "        df = pd.read_csv(input_file)\n",
        "        df = df.apply(pd.to_numeric, errors='coerce')  # Ensure all data is numeric\n",
        "\n",
        "        # Get relevant columns based on correlation\n",
        "        corr = get_corr(input_file, column='event_type')\n",
        "        cols_to_impute = [value for value, index in corr]  # Extract column names\n",
        "        df = df[cols_to_impute]\n",
        "\n",
        "        # Calculate missing value ratios\n",
        "        missing_ratio = df.isna().mean()\n",
        "\n",
        "        # Columns without missing values\n",
        "        notnan_cols = [col for col, ratio in missing_ratio.items() if ratio == 0.0]\n",
        "        # Columns with missing values\n",
        "        cols_to_impute = [col for col, ratio in missing_ratio.items() if ratio > 0.0]\n",
        "\n",
        "        print(\"📊 Missing value ratios:\")\n",
        "        print(missing_ratio[missing_ratio > 0])\n",
        "\n",
        "        features = df.copy()\n",
        "\n",
        "        original_data_dict = {}  # To store original data for RMSE calculation\n",
        "\n",
        "        # Progress bar for imputation\n",
        "        for col in tqdm(cols_to_impute, desc=\"🧠 Imputing columns\", ncols=100):\n",
        "            ratio = missing_ratio[col]\n",
        "\n",
        "            if ratio > drop_threshold:\n",
        "                print(f\"⚠️ Dropping column '{col}' due to high missing ratio ({ratio:.2%})\")\n",
        "                df.drop(columns=[col], inplace=True)\n",
        "                continue\n",
        "\n",
        "            temp_cols = notnan_cols + [col]\n",
        "            temp_data = features[temp_cols].copy()\n",
        "\n",
        "            if ratio > knn_threshold:\n",
        "                # Using GridSearchCV for IterativeImputer\n",
        "                param_grid = {'max_iter': [10, 50, 100], 'random_state': [0]}\n",
        "                imputer = IterativeImputer()\n",
        "                best_imputer, best_params = grid_search_imputation(imputer, param_grid, temp_data)\n",
        "                print(f\"Best IterativeImputer parameters for column '{col}': {best_params}\")\n",
        "            else:\n",
        "                # Using GridSearchCV for KNNImputer\n",
        "                param_grid = {'n_neighbors': [3, 5, 10, 15]}\n",
        "                imputer = KNNImputer()\n",
        "                best_imputer, best_params = grid_search_imputation(imputer, param_grid, temp_data)\n",
        "                print(f\"Best KNNImputer parameters for column '{col}': {best_params}\")\n",
        "\n",
        "            # Apply the best imputer to fill missing values\n",
        "            imputed = best_imputer.fit_transform(temp_data)\n",
        "            df[col] = imputed[:, -1]\n",
        "\n",
        "            # Store original data (non-NaN) and imputed data for RMSE calculation\n",
        "            original_data_dict[col] = {\n",
        "                'original': features[col].dropna().values,\n",
        "                'imputed': imputed[:, -1][~np.isnan(features[col].values)]\n",
        "            }\n",
        "\n",
        "        # Save the cleaned file\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"\\n✅ File saved successfully to: {output_file}\")\n",
        "\n",
        "        # Calculate RMSE and plot comparison\n",
        "        for col, data in original_data_dict.items():\n",
        "            original_data = data['original']\n",
        "            imputed_data = data['imputed']\n",
        "\n",
        "            # Calculate RMSE for each column\n",
        "            rmse_value = calculate_rmse(original_data, imputed_data)\n",
        "            print(f\"RMSE for column '{col}': {rmse_value:.4f}\")\n",
        "\n",
        "            # Plot comparison (scatter and histogram)\n",
        "            plot_comparison(original_data, imputed_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred: {e}\")\n",
        "\n",
        "\n",
        "# تنفيذ الدالة\n",
        "smart_impute_and_save(\n",
        "    input_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv',\n",
        "    output_file='/content/final_gridsearch.csv'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGc6mBzKGMzJ",
        "outputId": "c92b5a70-18dd-4221-96ec-b1de7840f281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Missing value ratios:\n",
            "bytes_toserver    0.006252\n",
            "pkts_toserver     0.006252\n",
            "tcp_flags         0.055555\n",
            "age               0.023725\n",
            "tcp_flags_ts      0.055555\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Imputing columns:   0%|                                                    | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNNImputer parameters for column 'bytes_toserver': {'n_neighbors': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file = '/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv'\n",
        "\n",
        "# Load the data 286149\n",
        "chunk_size = 1000000  # عدد الصفوف بالدفعة\n",
        "chunks = pd.read_csv(file, chunksize=chunk_size)\n",
        "target_col = 'event_type'\n",
        "\n",
        "for chunk in chunks:\n",
        "    # حساب مصفوفة الارتباط فقط بالنسبة للعمود المستهدف (Label)\n",
        "    corr = chunk.corr(method='pearson')[target_col]\n",
        "    #corr = chunk.corr(method='pearson')\n",
        "\n",
        "    # عرض المصفوفة كجدول مرتب\n",
        "    from IPython.display import display  # لو تعمل داخل jupyter أو colab\n",
        "    display(corr)\n",
        "\n",
        "    # عرض المصفوفة الحرارية (heatmap) مع اللون\n",
        "    plt.figure(figsize=(10, 8), dpi=500)\n",
        "    sns.heatmap(corr.T, annot=True, fmt=\".2f\", linewidth=.5, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    plt.title(f\"Correlation Matrix with {target_col}\")\n",
        "    plt.show()\n",
        "\n",
        "    break  # فقط أول دفعة"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "z6nFUS7UaAcn",
        "outputId": "5c321f15-1807-4632-edcd-65c4107072b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[proto            -0.009970\n",
              " event_type        1.000000\n",
              " flow_id           0.000410\n",
              " Date             -0.002510\n",
              " hour              0.006801\n",
              " minute            0.009804\n",
              " second            0.010652\n",
              " pkts_toclient     0.002509\n",
              " bytes_toserver    0.145608\n",
              " bytes_toclient    0.002508\n",
              " tcp_flags              NaN\n",
              " alerted           0.529017\n",
              " age                    NaN\n",
              " reason            0.619217\n",
              " pkts_toserver     0.295515\n",
              " tcp_flags_ts           NaN\n",
              " state             0.536614\n",
              " Name: event_type, dtype: float64]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'T'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d2f68f8a33ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# عرض المصفوفة الحرارية (heatmap) مع اللون\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".2f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coolwarm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Correlation Matrix with {target_col}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'T'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 5000x4000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA4up3e0gunz"
      },
      "outputs": [],
      "source": [
        "class NetworkPreprocessing:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "  def extract_tcp_option(self, option, key):\n",
        "    for opt in option:\n",
        "      if opt[0] == key:\n",
        "        return opt[1]\n",
        "    return None\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "  def convert_pcap_csv(self, pcap_file, csv_file):\n",
        "    try:\n",
        "      print(\"Countig packages...\")\n",
        "      with PcapReader(pcap_file) as count_reader:\n",
        "        total_packets = sum(1 for _ in count_reader)\n",
        "        print(f\"Total number of packages: {total_packets}\")\n",
        "\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with PcapReader(pcap_file) as packets:\n",
        "        with open(csv_file, mode='w', newline=\"\") as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([\n",
        "              \"Packet Number\", \"Ethernet DST\", \"Ethernet SRC\", \"Ethernet Type\",\n",
        "              \"IP Version\", \"IP IHL\", \"IP TOS\", \"IP Length\", \"IP ID\", \"IP Flags\",\n",
        "              \"IP Fragmentation\", \"IP TTL\", \"IP Proto\", \"IP Checksum\",\n",
        "              \"IP Src\", \"IP Dst\", \"TCP Src Port\", \"TCP Dst Port\", \"TCP Seq\",\n",
        "              \"TCP Ack\", \"TCP Data Offset\", \"TCP Reserved\", \"TCP Flags\",\n",
        "              \"TCP Window\", \"TCP Checksum\", \"TCP Urgent Pointer\", \"TCP Options MSS\",\n",
        "              \"TCP Options WScale\", \"TCP Options NOP\",\"Hexdump\"\n",
        "          ])\n",
        "\n",
        "          for i, packet in enumerate(tqdm(packets,total=total_packets, desc=\"Packet processing\")):\n",
        "            if packet.haslayer('Ethernet'):\n",
        "              eth_dst = packet['Ethernet'].dst\n",
        "              eth_src = packet['Ethernet'].src\n",
        "              eth_type = packet['Ethernet'].type\n",
        "            else:\n",
        "              eth_dst = eth_src = eth_type = None\n",
        "\n",
        "            if packet.haslayer('IP'):\n",
        "              ip_version = packet['IP'].version\n",
        "              ip_ihl = packet['IP'].ihl\n",
        "              ip_tos = packet['IP'].tos\n",
        "              ip_len = packet['IP'].len\n",
        "              ip_id = packet['IP'].id\n",
        "              ip_flags = packet['IP'].flags\n",
        "              ip_frag = packet['IP'].frag\n",
        "              ip_ttl = packet['IP'].ttl\n",
        "              ip_proto = packet['IP'].proto\n",
        "              ip_chksum = packet['IP'].chksum\n",
        "              ip_src = packet['IP'].src\n",
        "              ip_dst = packet['IP'].dst\n",
        "            else:\n",
        "              ip_version = ip_ihl = ip_tos = ip_len = ip_id = ip_flags = ip_frag = ip_ttl = ip_proto = ip_chksum = ip_src = ip_dst = None\n",
        "\n",
        "            if packet.haslayer('TCP'):\n",
        "              tcp_sport = packet['TCP'].sport\n",
        "              tcp_dport = packet['TCP'].dport\n",
        "              tcp_seq = packet['TCP'].seq\n",
        "              tcp_ack = packet['TCP'].ack\n",
        "              tcp_dataofs = packet['TCP'].dataofs\n",
        "              tcp_reserved = packet['TCP'].reserved\n",
        "              tcp_flags = packet['TCP'].flags\n",
        "              tcp_window = packet['TCP'].window\n",
        "              tcp_chksum = packet['TCP'].chksum\n",
        "              tcp_urgptr = packet['TCP'].urgptr\n",
        "              tcp_options = packet['TCP'].options\n",
        "\n",
        "              tcp_mss = self.extract_tcp_option(tcp_options, 'MSS')\n",
        "              tcp_wscale = self.extract_tcp_option(tcp_options, 'WScale')\n",
        "              tcp_nop_count = self.extract_tcp_option(tcp_options, 'NOP')\n",
        "\n",
        "            else:\n",
        "              tcp_sport = tcp_dport = tcp_seq = tcp_ack = tcp_dataofs = tcp_reserved = tcp_flags = tcp_window = tcp_chksum = tcp_urgptr = tcp_mss = tcp_wscale = tcp_nop_count = None\n",
        "\n",
        "            raw_data = packet.original.hex()\n",
        "            writer.writerow([\n",
        "                i + 1, eth_dst, eth_src, eth_type,\n",
        "                  ip_version, ip_ihl, ip_tos, ip_len, ip_id, ip_flags,\n",
        "                  ip_frag, ip_ttl, ip_proto, ip_chksum,\n",
        "                  ip_src, ip_dst, tcp_sport, tcp_dport, tcp_seq,\n",
        "                  tcp_ack, tcp_dataofs, tcp_reserved, tcp_flags,\n",
        "                  tcp_window, tcp_chksum, tcp_urgptr, tcp_mss, tcp_wscale, tcp_nop_count,\n",
        "                  raw_data\n",
        "            ])\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "a = NetworkPreprocessing()\n",
        "#a.convert_pcap_csv(pcap_file='/content/NGIDS/NGIDS-DS-v1/NGIDS.pcap',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/network.csv')\n",
        "#a.delete_data(file_path='/content/drive/MyDrive/hybrid_IDS/network.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0gugEuMgvIQ"
      },
      "outputs": [],
      "source": [
        "class PcapFileProcessing:\n",
        "  def __init__(self) -> None:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "\n",
        "  def date_time_columns(self, file_path, csv_file):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, dtype=str)\n",
        "        df.columns = df.columns.str.strip()\n",
        "        if 'timestamp' not in df.columns:\n",
        "            return \"Error: The 'timestamp' column is missing from the file.\"\n",
        "\n",
        "        df['timestamp'] = df['timestamp'].astype(str).str.strip()\n",
        "\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', dayfirst=True)\n",
        "\n",
        "        if df['timestamp'].isnull().all():\n",
        "            return \"All values in 'timestamp' are invalid and could not be converted.\"\n",
        "\n",
        "        # Extract date and time\n",
        "        df['date'] = df['timestamp'].dt.strftime('%d/%m/%Y')\n",
        "        df['time'] = df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "        # Save the result\n",
        "        df.to_csv(csv_file, index=False)\n",
        "\n",
        "        return \"Successfully converted 'timestamp' to 'date' and 'time'.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during conversion: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def convert_log_csv(self, log_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with open(log_file, \"r\") as logfile:\n",
        "        log_data = logfile.read()\n",
        "      pattern = re.compile(\n",
        "          r'(?P<timestamp>\\d{2}/\\d{2}/\\d{4}-\\d{2}:\\d{2}:\\d{2}\\.\\d+)\\s+\\[\\*\\*\\]\\s+\\[(?P<sid>[^]]+)\\]\\s+(?P<signature>.*?)\\s+\\[\\*\\*\\]\\s+\\[Classification:\\s+(?P<classification>.*?)\\]\\s+\\[Priority:\\s+(?P<priority>\\d+)\\]\\s+\\{(?P<protocol>\\w+)\\}\\s+(?P<src_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<src_port>\\d+)\\s+->\\s+(?P<dst_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<dst_port>\\d+)'\n",
        "          )\n",
        "      with open(csv_file, \"w\", newline=\"\") as csvfile:\n",
        "        fieldnames = ['timestamp', 'sid', 'signature', 'classification',\n",
        "                      'priority', 'protocol','src_ip', 'src_port', 'dst_ip', 'dst_port']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for match in pattern.finditer(log_data):\n",
        "          writer.writerow(match.groupdict())\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def convert_json_csv(self, json_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting JSON to CSV...\")\n",
        "      with open(json_file, 'r') as f:\n",
        "        data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "      fieldnames = set()\n",
        "      for row in data:\n",
        "          fieldnames.update(row.keys())\n",
        "\n",
        "      fieldnames = list(fieldnames)\n",
        "\n",
        "      with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(fieldnames)\n",
        "\n",
        "        for row in data:\n",
        "          writer.writerow(row.get(field, '') for field in fieldnames)\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "a = PcapFileProcessing()\n",
        "#a.convert_log_csv( log_file=\"/content/drive/MyDrive/hybrid_IDS/fast.log\",\n",
        "#                  csv_file=\"/content/drive/MyDrive/hybrid_IDS/alerts.csv\")\n",
        "\n",
        "#a.convert_json_csv(json_file='/content/drive/MyDrive/hybrid_IDS/eve.json',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "\n",
        "#a.delete_data( file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "a.date_time_columns(file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv',\n",
        "                    csv_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/hananbahtiti/Hybrid-Intrusion-detection-Systems/blob/main/NetworkPreprocessing.ipynb",
      "authorship_tag": "ABX9TyMxvD+2acGVwsyaTP01hxGW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}