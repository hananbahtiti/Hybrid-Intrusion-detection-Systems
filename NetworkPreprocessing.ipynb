{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hananbahtiti/Hybrid-Intrusion-detection-Systems/blob/main/NetworkPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "NFX9RSeDfiVY",
        "outputId": "28177a43-65c3-4dd6-9209-a5cc42e085e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scapy\n",
            "  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scapy\n",
            "Successfully installed scapy-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scapy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/eve_encoded.csv /content/drive/MyDrive/hybrid_IDS/dataset/"
      ],
      "metadata": {
        "id": "LBZjWIJjDPvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NSXj-h-NqUET",
        "outputId": "fb1a8fcf-b8ad-4d0a-834d-6e8071a58794",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 286150 entries, 0 to 286149\n",
            "Data columns (total 24 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   proto           286148 non-null  object \n",
            " 1   event_type      286150 non-null  object \n",
            " 2   flow_id         286048 non-null  float64\n",
            " 3   Date            286150 non-null  int64  \n",
            " 4   hour            137399 non-null  float64\n",
            " 5   minute          137399 non-null  float64\n",
            " 6   second          137399 non-null  float64\n",
            " 7   tcp_flags_tc    270253 non-null  float64\n",
            " 8   pkts_toclient   284361 non-null  float64\n",
            " 9   end             279361 non-null  object \n",
            " 10  rst             265083 non-null  object \n",
            " 11  syn             269185 non-null  object \n",
            " 12  ts_max_regions  269185 non-null  float64\n",
            " 13  bytes_toserver  284361 non-null  float64\n",
            " 14  bytes_toclient  284361 non-null  float64\n",
            " 15  tcp_flags       270253 non-null  float64\n",
            " 16  alerted         279361 non-null  object \n",
            " 17  start           284361 non-null  object \n",
            " 18  age             279361 non-null  float64\n",
            " 19  reason          279361 non-null  object \n",
            " 20  pkts_toserver   284361 non-null  float64\n",
            " 21  tc_max_regions  269185 non-null  float64\n",
            " 22  tcp_flags_ts    270253 non-null  float64\n",
            " 23  state           279361 non-null  object \n",
            "dtypes: float64(14), int64(1), object(9)\n",
            "memory usage: 52.4+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age\n",
              "15.0    139875\n",
              "16.0    124906\n",
              "0.0      14183\n",
              "8.0        148\n",
              "7.0        146\n",
              "1.0         76\n",
              "2.0          7\n",
              "4.0          2\n",
              "3.0          2\n",
              "36.0         1\n",
              "23.0         1\n",
              "22.0         1\n",
              "77.0         1\n",
              "41.0         1\n",
              "24.0         1\n",
              "28.0         1\n",
              "29.0         1\n",
              "25.0         1\n",
              "64.0         1\n",
              "82.0         1\n",
              "91.0         1\n",
              "43.0         1\n",
              "13.0         1\n",
              "66.0         1\n",
              "6.0          1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15.0</th>\n",
              "      <td>139875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16.0</th>\n",
              "      <td>124906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>14183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/hybrid_IDS/dataset/eve_tag.csv')\n",
        "df.info()\n",
        "df['age'].value_counts()\n",
        "#df['alert'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['proto'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "fm0abZx_LBfk",
        "outputId": "4c940a02-a241-4129-bcc4-172bf59bc408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "proto\n",
              "TCP     274551\n",
              "UDP      10603\n",
              "SCTP       694\n",
              "ICMP       200\n",
              "IPv6       100\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>proto</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TCP</th>\n",
              "      <td>274551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UDP</th>\n",
              "      <td>10603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCTP</th>\n",
              "      <td>694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ICMP</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IPv6</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "zFbcrLXbhOSk",
        "outputId": "ca08d4ef-0b4b-4361-bd09-3f677d787df9",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 286150 entries, 0 to 286149\n",
            "Data columns (total 17 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   proto           286148 non-null  object \n",
            " 1   event_type      286150 non-null  object \n",
            " 2   flow_id         286048 non-null  float64\n",
            " 3   Date            286150 non-null  int64  \n",
            " 4   hour            137399 non-null  float64\n",
            " 5   minute          137399 non-null  float64\n",
            " 6   second          137399 non-null  float64\n",
            " 7   pkts_toclient   284361 non-null  float64\n",
            " 8   bytes_toserver  284361 non-null  float64\n",
            " 9   bytes_toclient  284361 non-null  float64\n",
            " 10  tcp_flags       270253 non-null  float64\n",
            " 11  alerted         279361 non-null  object \n",
            " 12  age             279361 non-null  float64\n",
            " 13  reason          279361 non-null  object \n",
            " 14  pkts_toserver   284361 non-null  float64\n",
            " 15  tcp_flags_ts    270253 non-null  float64\n",
            " 16  state           279361 non-null  object \n",
            "dtypes: float64(11), int64(1), object(5)\n",
            "memory usage: 37.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  proto event_type       flow_id  Date  hour  minute  second  pkts_toclient  \\\n",
              "0   TCP      alert           NaN     0  17.0    49.0    10.0            NaN   \n",
              "1   TCP      alert  2.558362e+14     0  17.0    49.0    44.0            0.0   \n",
              "2   TCP      alert  2.558362e+14     0  17.0    49.0    44.0            0.0   \n",
              "3   UDP       tftp  5.620575e+13     0  17.0    49.0    36.0            NaN   \n",
              "4   TCP       flow  8.582737e+14     0  17.0    48.0    59.0            0.0   \n",
              "\n",
              "   bytes_toserver  bytes_toclient  tcp_flags alerted  age   reason  \\\n",
              "0             NaN             NaN        NaN     NaN  NaN      NaN   \n",
              "1            62.0             0.0        NaN     NaN  NaN      NaN   \n",
              "2            62.0             0.0        NaN     NaN  NaN      NaN   \n",
              "3             NaN             NaN        NaN     NaN  NaN      NaN   \n",
              "4            60.0             0.0        0.0   False  0.0  timeout   \n",
              "\n",
              "   pkts_toserver  tcp_flags_ts state  \n",
              "0            NaN           NaN   NaN  \n",
              "1            1.0           NaN   NaN  \n",
              "2            1.0           NaN   NaN  \n",
              "3            NaN           NaN   NaN  \n",
              "4            1.0           0.0   new  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea15ce8e-c2af-43f4-8919-2f8bf527d22e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proto</th>\n",
              "      <th>event_type</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "      <th>pkts_toclient</th>\n",
              "      <th>bytes_toserver</th>\n",
              "      <th>bytes_toclient</th>\n",
              "      <th>tcp_flags</th>\n",
              "      <th>alerted</th>\n",
              "      <th>age</th>\n",
              "      <th>reason</th>\n",
              "      <th>pkts_toserver</th>\n",
              "      <th>tcp_flags_ts</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCP</td>\n",
              "      <td>alert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCP</td>\n",
              "      <td>alert</td>\n",
              "      <td>2.558362e+14</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCP</td>\n",
              "      <td>alert</td>\n",
              "      <td>2.558362e+14</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UDP</td>\n",
              "      <td>tftp</td>\n",
              "      <td>5.620575e+13</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCP</td>\n",
              "      <td>flow</td>\n",
              "      <td>8.582737e+14</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>timeout</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>new</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea15ce8e-c2af-43f4-8919-2f8bf527d22e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea15ce8e-c2af-43f4-8919-2f8bf527d22e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea15ce8e-c2af-43f4-8919-2f8bf527d22e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4d52fb55-b3fc-4cc5-a2f9-11944337a1d1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d52fb55-b3fc-4cc5-a2f9-11944337a1d1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4d52fb55-b3fc-4cc5-a2f9-11944337a1d1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df = pd.read_csv('/content/eve.csv')\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZCP9zxIaglIA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import ast\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from tqdm import tqdm\n",
        "    TQDM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TQDM_AVAILABLE = False"
      ],
      "metadata": {
        "id": "xqC3EGR9hY_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "aK3sW0cEkbB_",
        "outputId": "10438898-941d-426b-cf36-9bd97237bbcc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Missing value ratio per column:\n",
            " proto             0.000000\n",
            "event_type        0.000000\n",
            "flow_id           0.000356\n",
            "Date              0.000000\n",
            "hour              0.519836\n",
            "minute            0.519836\n",
            "second            0.519836\n",
            "pkts_toclient     0.006252\n",
            "bytes_toserver    0.006252\n",
            "bytes_toclient    0.006252\n",
            "tcp_flags         0.055555\n",
            "alerted           0.000000\n",
            "age               0.023725\n",
            "reason            0.000000\n",
            "pkts_toserver     0.006252\n",
            "tcp_flags_ts      0.055555\n",
            "state             0.000000\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rImputing columns:   0%|          | 0/11 [00:00<?, ?column/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing column: flow_id (Missing 0.04%) ===\n",
            "üõ†Ô∏è  Using Iterative Imputer for flow_id...\n",
            "\n",
            "=== Processing column: hour (Missing 51.98%) ===\n",
            "üîç Using KNN Imputer for hour...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rImputing columns:   9%|‚ñâ         | 1/11 [00:12<02:00, 12.09s/column]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8cb5b0dd0953>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;31m#a.data_encoding(file_path='/content/eve.csv',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m  \u001b[0;31m#              columns_names=c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m a.smart_impute_and_save( input_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv',\n\u001b[0m\u001b[1;32m    249\u001b[0m                         output_file='/content/eve_output.csv')\n",
            "\u001b[0;32m<ipython-input-11-8cb5b0dd0953>\u001b[0m in \u001b[0;36msmart_impute_and_save\u001b[0;34m(self, input_file, output_file)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# Using KNNImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mimputed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         )\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;31m# process_chunk modifies X in place. No return value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2253\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   2254\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2478\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mnan_euclidean_distances\u001b[0;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0mXX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mYY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class Preprocessing:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def clean_and_save(self, file_path: str, output_path: str, threshold=80):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        total_rows = len(df)\n",
        "        missing_ratios = (df.isnull().sum() / total_rows) * 100\n",
        "\n",
        "        columns_to_drop = [col for col, ratio in missing_ratios.items() if ratio > threshold]\n",
        "\n",
        "        print(f\"Columns to drop: {columns_to_drop}\")\n",
        "\n",
        "        df = df.drop(columns=columns_to_drop, axis=1)\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return f\"Saved cleaned data to {output_path}\"\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def columns_drop(self, file_path: str, columns_names: list, output_path: str):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df.drop(columns=columns_names, axis=1)  # Drop columns once\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return f\"Saved cleaned data to {output_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def data_encoding(self, file_path, columns_names: list):\n",
        "    encoder = LabelEncoder()\n",
        "    tqdm.pandas()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)  # ŸÇÿ±ÿßÿ°ÿ© ÿßŸÑŸÖŸÑŸÅ ŸÖÿ±ÿ© Ÿàÿßÿ≠ÿØÿ© ŸÅŸÇÿ∑\n",
        "\n",
        "        for col in columns_names:\n",
        "            df.loc[:, col] = df.loc[:, col].fillna(\"-1\").astype(str)\n",
        "\n",
        "            encoder.fit(df.loc[:, col])\n",
        "\n",
        "            # ÿ™ÿ≠ÿØŸäÿ´ ÿ¥ÿ±Ÿäÿ∑ ÿßŸÑÿ™ŸÇÿØŸÖ ÿ®ÿ≠Ÿäÿ´ Ÿäÿ∏Ÿáÿ± ÿßÿ≥ŸÖ ÿßŸÑÿπŸÖŸàÿØ\n",
        "            with tqdm(total=len(df), desc=f\"Encoding '{col}'\", unit=\"rows\") as pbar:\n",
        "                def encoding_function(x):\n",
        "                    result = encoder.transform([x])[0] if pd.notna(x) else -1\n",
        "                    pbar.update(1)\n",
        "                    return result\n",
        "\n",
        "                df.loc[:, col] = df.loc[:, col].apply(encoding_function)\n",
        "\n",
        "        output_path = file_path.replace(\".csv\", \"_encoded.csv\")\n",
        "        df.to_csv(output_path, index=False)\n",
        "        return f\"Done. Encoded file saved to: {output_path}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "  def drop_constant_columns(self, file_path, output_path=None):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        constant_columns = [col for col in df.columns if df[col].nunique(dropna=True) == 1]\n",
        "        print(f\"Columns with constant value: {constant_columns}\")\n",
        "\n",
        "        df = df.drop(columns=constant_columns)\n",
        "        if output_path is None:\n",
        "          output_path = file_path.replace('.csv', '_no_constant.csv')\n",
        "        df.to_csv(output_path, index=False)\n",
        "\n",
        "        return f\"Saved cleaned file to {output_path}\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "  def show_column_types(self, file_path):\n",
        "    try:\n",
        "      columns_names = []\n",
        "      df = pd.read_csv(file_path)\n",
        "      [columns_names.append(col)  for col in df.columns if df[col].dtype == 'object']\n",
        "\n",
        "      return columns_names\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def expand_dict_columns( file_path, column_names: list, output_file_path: str = None):\n",
        "      try:\n",
        "          df = pd.read_csv(file_path)\n",
        "\n",
        "          all_keys = set()\n",
        "\n",
        "          # Step 1: Extract all keys\n",
        "          def extract_keys(value):\n",
        "              if pd.notna(value):\n",
        "                  try:\n",
        "                      return ast.literal_eval(value).keys()\n",
        "                  except (SyntaxError, ValueError):\n",
        "                      return []\n",
        "              return []\n",
        "\n",
        "          print(\"üîç Extracting all keys...\")\n",
        "\n",
        "          for column_name in column_names:\n",
        "              if column_name in df.columns:\n",
        "                  all_keys.update(df[column_name].apply(extract_keys).explode().dropna().unique())\n",
        "\n",
        "          print(f\"‚úÖ Extracted {len(all_keys)} unique keys.\")\n",
        "\n",
        "          # Step 2: Create new columns and fill values\n",
        "          if TQDM_AVAILABLE:\n",
        "              progress_bar = tqdm(all_keys, desc=\"üöÄ Expanding values\", ncols=80)\n",
        "          else:\n",
        "              progress_bar = all_keys\n",
        "\n",
        "          for idx, key in enumerate(progress_bar):\n",
        "              df[key] = np.nan\n",
        "              for column_name in column_names:\n",
        "                  if column_name in df.columns:\n",
        "                      df[key] = df[key].combine_first(\n",
        "                          df[column_name].apply(lambda x: Preprocessing.expand_dict_column(x, key))\n",
        "                      )\n",
        "\n",
        "              # Print manual progress if tqdm is not available\n",
        "              if not TQDM_AVAILABLE and idx % max(1, len(all_keys)//10) == 0:\n",
        "                  print(f\"üìà Progress: {idx}/{len(all_keys)} keys expanded...\")\n",
        "\n",
        "          # Step 3: Drop original dictionary columns\n",
        "          df = df.drop(columns=column_names, axis=1)\n",
        "\n",
        "          # Step 4: Save the new file\n",
        "          output_file_path = output_file_path or file_path.replace(\".csv\", \"_expanded.csv\")\n",
        "          df.to_csv(output_file_path, index=False)\n",
        "\n",
        "          return f\"‚úÖ Columns expanded and file saved successfully at: {output_file_path}\"\n",
        "\n",
        "      except Exception as e:\n",
        "          return f\"‚ùå An error occurred: {e}\"\n",
        "\n",
        "  @staticmethod\n",
        "  def expand_dict_column( value, column_name):\n",
        "      if pd.notna(value):\n",
        "          try:\n",
        "              dictionary = ast.literal_eval(value)\n",
        "              return dictionary.get(column_name, np.nan)\n",
        "          except (SyntaxError, ValueError):\n",
        "              return np.nan\n",
        "      return np.nan\n",
        "\n",
        "\n",
        "\n",
        "  def smart_impute_and_save(self, input_file, output_file):\n",
        "    \"\"\"\n",
        "    This method automatically fills missing values based on missing ratios,\n",
        "    then saves the cleaned data to a new CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        start_time = time.time()  # Start timing ‚è±Ô∏è\n",
        "\n",
        "        # Load the data\n",
        "        df = pd.read_csv(input_file)\n",
        "        #df = next(chunks)  # Read the first chunk\n",
        "\n",
        "        # Define columns with missing values\n",
        "        cols_to_impute = [\n",
        "            'flow_id', 'hour', 'minute', 'second',\n",
        "            'pkts_toclient', 'bytes_toserver', 'bytes_toclient',\n",
        "            'tcp_flags', 'age', 'pkts_toserver', 'tcp_flags_ts'\n",
        "        ]\n",
        "\n",
        "        # Remove duplicate columns (optional if data has repeated names)\n",
        "        df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "        # Build the feature set\n",
        "        features = df.copy()\n",
        "\n",
        "        # Calculate missing value ratios\n",
        "        missing_ratio = features.isna().mean()\n",
        "        print(\"üìä Missing value ratio per column:\\n\", missing_ratio)\n",
        "\n",
        "        # Smart imputation\n",
        "        for col in tqdm(cols_to_impute, desc=\"Imputing columns\", unit=\"column\"):\n",
        "            if col not in df.columns:\n",
        "                continue  # Skip if the column was dropped or doesn't exist\n",
        "\n",
        "            ratio = missing_ratio[col]\n",
        "            print(f\"\\n=== Processing column: {col} (Missing {ratio:.2%}) ===\")\n",
        "\n",
        "            if ratio > 0.90:\n",
        "                print(f\"‚ö†Ô∏è  Column {col} has too many missing values (>95%). Dropping it...\")\n",
        "                df.drop(columns=[col], inplace=True)\n",
        "\n",
        "            elif ratio < 0.3:\n",
        "                print(f\"üõ†Ô∏è  Using Iterative Imputer for {col}...\")\n",
        "                imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "\n",
        "                temp_data = features[[col]]\n",
        "\n",
        "                # Using IterativeImputer\n",
        "                imputed_data = imputer.fit_transform(temp_data)\n",
        "                df[col] = imputed_data[:, 0]\n",
        "\n",
        "            else:\n",
        "                print(f\"üîç Using KNN Imputer for {col}...\")\n",
        "                imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "                temp_data = features[[col]]\n",
        "\n",
        "                # Using KNNImputer\n",
        "                imputed_data = imputer.fit_transform(temp_data)\n",
        "                df[col] = imputed_data[:, 0]\n",
        "\n",
        "        # Save the cleaned data\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"\\n‚úÖ Successfully completed missing value filling and saved to {output_file}.\")\n",
        "\n",
        "        end_time = time.time()  # End timing ‚è±Ô∏è\n",
        "        elapsed_time = end_time - start_time\n",
        "        print(f\"‚è±Ô∏è Total execution time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "a = Preprocessing()\n",
        "#a.data_encoding('/content/drive/MyDrive/hybrid_IDS/dataset/eve.csv',\n",
        "#                column_number=19)\n",
        "\n",
        "#a.clean_and_save(file_path='/content/eve_del_expanded.csv',\n",
        " #                output_path='/content/eve_tag.csv', threshold=80)\n",
        "#a.expand_dict_columns( file_path='/content/eve_del.csv',\n",
        " #                    column_names=['tcp' , 'flow'])\n",
        "#a.drop_constant_columns(file_path='/content/eve_tag.csv')\n",
        "\n",
        "#c= a.show_column_types( file_path='/content/eve.csv')\n",
        "#a.data_encoding(file_path='/content/eve.csv',\n",
        " #              columns_names=c)\n",
        "a.smart_impute_and_save( input_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv',\n",
        "                        output_file='/content/eve_output.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv'\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv(file)\n",
        "target_col = 'event_type'\n",
        "\n",
        "corr = df.corr(method='pearson')[target_col]\n",
        "corr_series = pd.Series(dict(corr.items()))\n",
        "[print(f\"column {value}:  {index}\") for value, index in corr_series.sort_values().items() if abs(index) > 0.05 ]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvBYUAJMgNNQ",
        "outputId": "f11f6ca4-b277-442f-be56-6e1caf58877e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "column bytes_toserver:  0.1456078888145592\n",
            "column pkts_toserver:  0.29551471735508295\n",
            "column alerted:  0.5290174299124204\n",
            "column state:  0.5366141360719512\n",
            "column reason:  0.6192174484866461\n",
            "column event_type:  1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file = '/content/drive/MyDrive/hybrid_IDS/dataset/eve_encoded.csv'\n",
        "\n",
        "# Load the data 286149\n",
        "chunk_size = 1000000  # ÿπÿØÿØ ÿßŸÑÿµŸÅŸàŸÅ ÿ®ÿßŸÑÿØŸÅÿπÿ©\n",
        "chunks = pd.read_csv(file, chunksize=chunk_size)\n",
        "target_col = 'event_type'\n",
        "\n",
        "for chunk in chunks:\n",
        "    # ÿ≠ÿ≥ÿßÿ® ŸÖÿµŸÅŸàŸÅÿ© ÿßŸÑÿßÿ±ÿ™ÿ®ÿßÿ∑ ŸÅŸÇÿ∑ ÿ®ÿßŸÑŸÜÿ≥ÿ®ÿ© ŸÑŸÑÿπŸÖŸàÿØ ÿßŸÑŸÖÿ≥ÿ™ŸáÿØŸÅ (Label)\n",
        "    corr = chunk.corr(method='pearson')[target_col]\n",
        "    #corr = chunk.corr(method='pearson')\n",
        "\n",
        "    # ÿπÿ±ÿ∂ ÿßŸÑŸÖÿµŸÅŸàŸÅÿ© ŸÉÿ¨ÿØŸàŸÑ ŸÖÿ±ÿ™ÿ®\n",
        "    from IPython.display import display  # ŸÑŸà ÿ™ÿπŸÖŸÑ ÿØÿßÿÆŸÑ jupyter ÿ£Ÿà colab\n",
        "    display(corr)\n",
        "\n",
        "    # ÿπÿ±ÿ∂ ÿßŸÑŸÖÿµŸÅŸàŸÅÿ© ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© (heatmap) ŸÖÿπ ÿßŸÑŸÑŸàŸÜ\n",
        "    plt.figure(figsize=(10, 8), dpi=500)\n",
        "    sns.heatmap(corr.T, annot=True, fmt=\".2f\", linewidth=.5, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    plt.title(f\"Correlation Matrix with {target_col}\")\n",
        "    plt.show()\n",
        "\n",
        "    break  # ŸÅŸÇÿ∑ ÿ£ŸàŸÑ ÿØŸÅÿπÿ©"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "z6nFUS7UaAcn",
        "outputId": "5c321f15-1807-4632-edcd-65c4107072b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[proto            -0.009970\n",
              " event_type        1.000000\n",
              " flow_id           0.000410\n",
              " Date             -0.002510\n",
              " hour              0.006801\n",
              " minute            0.009804\n",
              " second            0.010652\n",
              " pkts_toclient     0.002509\n",
              " bytes_toserver    0.145608\n",
              " bytes_toclient    0.002508\n",
              " tcp_flags              NaN\n",
              " alerted           0.529017\n",
              " age                    NaN\n",
              " reason            0.619217\n",
              " pkts_toserver     0.295515\n",
              " tcp_flags_ts           NaN\n",
              " state             0.536614\n",
              " Name: event_type, dtype: float64]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'T'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d2f68f8a33ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# ÿπÿ±ÿ∂ ÿßŸÑŸÖÿµŸÅŸàŸÅÿ© ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© (heatmap) ŸÖÿπ ÿßŸÑŸÑŸàŸÜ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".2f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coolwarm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Correlation Matrix with {target_col}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'T'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 5000x4000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.columns_drop( file_path='/content/eve_tag_no_constant.csv',\n",
        "               columns_names=['start', 'end'], output_path='/content/eve.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L1WQG0rZFQKb",
        "outputId": "46fb61cf-59c6-41ae-cb44-6d17ca52c477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Saved cleaned data to /content/eve.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz1DjfWQ-TdV",
        "outputId": "f9836210-6cce-4202-d5cb-61089cccef8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['proto', 'event_type', 'end', 'alerted', 'start', 'reason', 'state']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA4up3e0gunz"
      },
      "outputs": [],
      "source": [
        "class NetworkPreprocessing:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "  def extract_tcp_option(self, option, key):\n",
        "    for opt in option:\n",
        "      if opt[0] == key:\n",
        "        return opt[1]\n",
        "    return None\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "  def convert_pcap_csv(self, pcap_file, csv_file):\n",
        "    try:\n",
        "      print(\"Countig packages...\")\n",
        "      with PcapReader(pcap_file) as count_reader:\n",
        "        total_packets = sum(1 for _ in count_reader)\n",
        "        print(f\"Total number of packages: {total_packets}\")\n",
        "\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with PcapReader(pcap_file) as packets:\n",
        "        with open(csv_file, mode='w', newline=\"\") as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([\n",
        "              \"Packet Number\", \"Ethernet DST\", \"Ethernet SRC\", \"Ethernet Type\",\n",
        "              \"IP Version\", \"IP IHL\", \"IP TOS\", \"IP Length\", \"IP ID\", \"IP Flags\",\n",
        "              \"IP Fragmentation\", \"IP TTL\", \"IP Proto\", \"IP Checksum\",\n",
        "              \"IP Src\", \"IP Dst\", \"TCP Src Port\", \"TCP Dst Port\", \"TCP Seq\",\n",
        "              \"TCP Ack\", \"TCP Data Offset\", \"TCP Reserved\", \"TCP Flags\",\n",
        "              \"TCP Window\", \"TCP Checksum\", \"TCP Urgent Pointer\", \"TCP Options MSS\",\n",
        "              \"TCP Options WScale\", \"TCP Options NOP\",\"Hexdump\"\n",
        "          ])\n",
        "\n",
        "          for i, packet in enumerate(tqdm(packets,total=total_packets, desc=\"Packet processing\")):\n",
        "            if packet.haslayer('Ethernet'):\n",
        "              eth_dst = packet['Ethernet'].dst\n",
        "              eth_src = packet['Ethernet'].src\n",
        "              eth_type = packet['Ethernet'].type\n",
        "            else:\n",
        "              eth_dst = eth_src = eth_type = None\n",
        "\n",
        "            if packet.haslayer('IP'):\n",
        "              ip_version = packet['IP'].version\n",
        "              ip_ihl = packet['IP'].ihl\n",
        "              ip_tos = packet['IP'].tos\n",
        "              ip_len = packet['IP'].len\n",
        "              ip_id = packet['IP'].id\n",
        "              ip_flags = packet['IP'].flags\n",
        "              ip_frag = packet['IP'].frag\n",
        "              ip_ttl = packet['IP'].ttl\n",
        "              ip_proto = packet['IP'].proto\n",
        "              ip_chksum = packet['IP'].chksum\n",
        "              ip_src = packet['IP'].src\n",
        "              ip_dst = packet['IP'].dst\n",
        "            else:\n",
        "              ip_version = ip_ihl = ip_tos = ip_len = ip_id = ip_flags = ip_frag = ip_ttl = ip_proto = ip_chksum = ip_src = ip_dst = None\n",
        "\n",
        "            if packet.haslayer('TCP'):\n",
        "              tcp_sport = packet['TCP'].sport\n",
        "              tcp_dport = packet['TCP'].dport\n",
        "              tcp_seq = packet['TCP'].seq\n",
        "              tcp_ack = packet['TCP'].ack\n",
        "              tcp_dataofs = packet['TCP'].dataofs\n",
        "              tcp_reserved = packet['TCP'].reserved\n",
        "              tcp_flags = packet['TCP'].flags\n",
        "              tcp_window = packet['TCP'].window\n",
        "              tcp_chksum = packet['TCP'].chksum\n",
        "              tcp_urgptr = packet['TCP'].urgptr\n",
        "              tcp_options = packet['TCP'].options\n",
        "\n",
        "              tcp_mss = self.extract_tcp_option(tcp_options, 'MSS')\n",
        "              tcp_wscale = self.extract_tcp_option(tcp_options, 'WScale')\n",
        "              tcp_nop_count = self.extract_tcp_option(tcp_options, 'NOP')\n",
        "\n",
        "            else:\n",
        "              tcp_sport = tcp_dport = tcp_seq = tcp_ack = tcp_dataofs = tcp_reserved = tcp_flags = tcp_window = tcp_chksum = tcp_urgptr = tcp_mss = tcp_wscale = tcp_nop_count = None\n",
        "\n",
        "            raw_data = packet.original.hex()\n",
        "            writer.writerow([\n",
        "                i + 1, eth_dst, eth_src, eth_type,\n",
        "                  ip_version, ip_ihl, ip_tos, ip_len, ip_id, ip_flags,\n",
        "                  ip_frag, ip_ttl, ip_proto, ip_chksum,\n",
        "                  ip_src, ip_dst, tcp_sport, tcp_dport, tcp_seq,\n",
        "                  tcp_ack, tcp_dataofs, tcp_reserved, tcp_flags,\n",
        "                  tcp_window, tcp_chksum, tcp_urgptr, tcp_mss, tcp_wscale, tcp_nop_count,\n",
        "                  raw_data\n",
        "            ])\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "a = NetworkPreprocessing()\n",
        "#a.convert_pcap_csv(pcap_file='/content/NGIDS/NGIDS-DS-v1/NGIDS.pcap',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/network.csv')\n",
        "#a.delete_data(file_path='/content/drive/MyDrive/hybrid_IDS/network.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0gugEuMgvIQ"
      },
      "outputs": [],
      "source": [
        "class PcapFileProcessing:\n",
        "  def __init__(self) -> None:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "  def delete_data(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.loc[:, df.nunique() > 1]\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return f\"Columns containing only one value are deleted...\"\n",
        "\n",
        "\n",
        "  def date_time_columns(self, file_path, csv_file):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, dtype=str)\n",
        "        df.columns = df.columns.str.strip()\n",
        "        if 'timestamp' not in df.columns:\n",
        "            return \"Error: The 'timestamp' column is missing from the file.\"\n",
        "\n",
        "        df['timestamp'] = df['timestamp'].astype(str).str.strip()\n",
        "\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', dayfirst=True)\n",
        "\n",
        "        if df['timestamp'].isnull().all():\n",
        "            return \"All values in 'timestamp' are invalid and could not be converted.\"\n",
        "\n",
        "        # Extract date and time\n",
        "        df['date'] = df['timestamp'].dt.strftime('%d/%m/%Y')\n",
        "        df['time'] = df['timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "        # Save the result\n",
        "        df.to_csv(csv_file, index=False)\n",
        "\n",
        "        return \"Successfully converted 'timestamp' to 'date' and 'time'.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during conversion: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def convert_log_csv(self, log_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting to csv file...\")\n",
        "      with open(log_file, \"r\") as logfile:\n",
        "        log_data = logfile.read()\n",
        "      pattern = re.compile(\n",
        "          r'(?P<timestamp>\\d{2}/\\d{2}/\\d{4}-\\d{2}:\\d{2}:\\d{2}\\.\\d+)\\s+\\[\\*\\*\\]\\s+\\[(?P<sid>[^]]+)\\]\\s+(?P<signature>.*?)\\s+\\[\\*\\*\\]\\s+\\[Classification:\\s+(?P<classification>.*?)\\]\\s+\\[Priority:\\s+(?P<priority>\\d+)\\]\\s+\\{(?P<protocol>\\w+)\\}\\s+(?P<src_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<src_port>\\d+)\\s+->\\s+(?P<dst_ip>\\d+\\.\\d+\\.\\d+\\.\\d+):(?P<dst_port>\\d+)'\n",
        "          )\n",
        "      with open(csv_file, \"w\", newline=\"\") as csvfile:\n",
        "        fieldnames = ['timestamp', 'sid', 'signature', 'classification',\n",
        "                      'priority', 'protocol','src_ip', 'src_port', 'dst_ip', 'dst_port']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for match in pattern.finditer(log_data):\n",
        "          writer.writerow(match.groupdict())\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "  def convert_json_csv(self, json_file, csv_file):\n",
        "    try:\n",
        "      print(\"Start converting JSON to CSV...\")\n",
        "      with open(json_file, 'r') as f:\n",
        "        data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "      fieldnames = set()\n",
        "      for row in data:\n",
        "          fieldnames.update(row.keys())\n",
        "\n",
        "      fieldnames = list(fieldnames)\n",
        "\n",
        "      with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(fieldnames)\n",
        "\n",
        "        for row in data:\n",
        "          writer.writerow(row.get(field, '') for field in fieldnames)\n",
        "\n",
        "      return f\"The file has been converted to csv successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "      return f\"An error occurred: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "a = PcapFileProcessing()\n",
        "#a.convert_log_csv( log_file=\"/content/drive/MyDrive/hybrid_IDS/fast.log\",\n",
        "#                  csv_file=\"/content/drive/MyDrive/hybrid_IDS/alerts.csv\")\n",
        "\n",
        "#a.convert_json_csv(json_file='/content/drive/MyDrive/hybrid_IDS/eve.json',\n",
        "#                   csv_file='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "\n",
        "#a.delete_data( file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv')\n",
        "a.date_time_columns(file_path='/content/drive/MyDrive/hybrid_IDS/eve.csv',\n",
        "                    csv_file='/content/drive/MyDrive/hybrid_IDS/dataset/eve.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/hananbahtiti/Hybrid-Intrusion-detection-Systems/blob/main/NetworkPreprocessing.ipynb",
      "authorship_tag": "ABX9TyM4azkPsX9cOzLuLXfFG+il",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}